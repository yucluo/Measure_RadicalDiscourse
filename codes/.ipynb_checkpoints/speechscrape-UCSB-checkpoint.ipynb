{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base URL for scrapping\n",
    "root = 'https://www.presidency.ucsb.edu'\n",
    "\n",
    "# search based on name, title, and date\n",
    "# date is between 1) receives party nomination and 2) election day \n",
    "# cand_dict = {1: {'first': 'George-w', 'last': 'Bush', 'title': 'President', 'start': date(2000, 8, 3), 'end': date(2000, 12, 12)},#2000\n",
    "#              2: {'first': 'Albert', 'last': 'Gore-jr', 'title': 'VP', 'start': date(2000, 8, 17), 'end': date(2000, 12, 12)},\n",
    "#              3: {'first': 'George-w', 'last': 'Bush', 'title': 'President', 'start': date(2004, 9, 2), 'end': date(2004, 11, 2)}, #2004\n",
    "#              4: {'first': 'John-f', 'last': 'Kerry', 'title': 'Senator', 'start': date(2004, 7, 29), 'end': date(2004, 11, 2)},\n",
    "#              5: {'first': 'Barack', 'last': 'Obama', 'title': 'President', 'start': date(2008, 8, 28), 'end': date(2008, 11, 3)},#2008\n",
    "#              6: {'first': 'John', 'last': 'McCain', 'title': 'Senator', 'start': date(2008, 9, 4), 'end': date(2008, 11, 3)}, \n",
    "#              7: {'first': 'Barack', 'last': 'Obama', 'title': 'President', 'start': date(2012, 9, 6), 'end': date(2012, 11, 6)},#2012\n",
    "#              8: {'first': 'Mitt', 'last': 'Romney', 'title': 'Governor', 'start': date(2012, 8, 30), 'end': date(2012, 11, 6)},\n",
    "#              9: {'first': 'Donald-j', 'last': 'Trump', 'title': 'President', 'start': date(2016, 7, 21), 'end': date(2016, 11, 8)}, #2016\n",
    "#              10: {'first': 'Hillary', 'last': 'Clinton', 'title': 'Secretary', 'start': date(2016, 7, 28), 'end': date(2016, 11, 8)}}\n",
    "cand_dict = {1: {'first': 'Donald-j', 'last': 'Trump', 'title': 'President', 'start': date(2020, 3, 17), 'end': date(2020, 11, 3)},#2020\n",
    "              2: {'first': 'Joseph-r', 'last': 'Biden', 'title': 'President', 'start': date(2020, 8, 18), 'end': date(2020, 11, 3)},}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape, write txt and meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-9f2d5f44a46b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeechdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mlengthbefore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for cand in range(1,3):  \n",
    "    #create candidate specific url string\n",
    "    if cand_dict[cand]['title'] == \"President\":\n",
    "        candidate = '/people/president/' + cand_dict[cand]['first'] + '-' + cand_dict[cand]['last'] + '?page=' \n",
    "    else:\n",
    "        candidate = '/people/other/' + cand_dict[cand]['first'] + '-' + cand_dict[cand]['last'] + '?page=' \n",
    "    candidate_iter = 0\n",
    "\n",
    "    speech_path = 'speeches_' + cand_dict[cand]['last'].lower() + '_ucsb'\n",
    "    try:  \n",
    "        os.mkdir(speech_path)\n",
    "    except OSError:\n",
    "        pass\n",
    "    # first go into candidate page\n",
    "    r = requests.get(root + candidate.lower() + str(candidate_iter))\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    # locate the final page\n",
    "    try: \n",
    "        fin = soup.find_all('a', title = 'Go to last page')\n",
    "     # find max page number\n",
    "        max_p = int(re.findall(r'page=([0-9]+)', str(fin[0]))[0])\n",
    "    except: \n",
    "        max_p = 1\n",
    "\n",
    "\n",
    "    # initialize metadata dict\n",
    "    metadata = defaultdict(list)\n",
    "\n",
    "    for iter in range(candidate_iter, max_p + 1):\n",
    "\n",
    "        r = requests.get(root + candidate.lower() + str(iter))\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        titles_raw = soup.findAll(class_=\"views-field views-field-title\")\n",
    "        dates_raw = soup.findAll(class_=\"field-docs-start-date-time\")\n",
    "        \n",
    "        if dates_raw\n",
    "        links = []\n",
    "        for x in titles_raw:\n",
    "            links.append(x.a['href'])\n",
    "        titles = []\n",
    "        for x in titles_raw:\n",
    "            titles.append(x.a.contents[0])\n",
    "        dates = []\n",
    "        for x in dates_raw: \n",
    "            date_raw = re.findall(r'content=\"([0-9]{4})-([0-9]{2})-([0-9]{2})', str(x))\n",
    "            if int(date_raw[0][0]) < 1980 or int(date_raw[0][0]) > 2020:\n",
    "                continue\n",
    "            speechdate = date(int(date_raw[0][0]), int(date_raw[0][1]), int(date_raw[0][2]))\n",
    "            dates.append(speechdate)\n",
    "\n",
    "        assert len(links) == len(titles) == len(dates)\n",
    "\n",
    "        lengthbefore = len(metadata)\n",
    "\n",
    "        for i in range(len(metadata), len(metadata) + len(links)):\n",
    "            metadata[i] = [links[i - lengthbefore], titles[i - lengthbefore], dates[i - lengthbefore]]\n",
    "\n",
    "### start extracting speeches that fit our parameters\n",
    "    speechnum = 0\n",
    "\n",
    "    meta = [] # also save meta of those speeches separately \n",
    "    for i in range(0, len(metadata)):\n",
    "        # only keep within the pre-specified dates, and only if it comes with \"remarks\"\n",
    "        if metadata[i][2] >= cand_dict[cand]['start'] and metadata[i][2] <= cand_dict[cand]['end'] and (\"remarks\" in metadata[i][1].lower() or (\"address\" in metadata[i][1].lower() and \"nomination\" in metadata[i][1].lower())): \n",
    "            speechnum += 1\n",
    "            r = requests.get(root + metadata[i][0])\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            text_full = soup.findAll(class_='field-docs-content')[0].get_text()\n",
    "            text = text_full\n",
    "            try:\n",
    "                location = soup.findAll(class_=\"field-spot-state\")[0].get_text()\n",
    "                metadata[i].append(location)\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                filename = cand_dict[cand]['last'].lower() + '-speech-' + str(metadata[i][2]) + '-' + re.findall('[\\w]+-[\\w]+-[\\w]+$', metadata[i][0])[0]\n",
    "                print(filename)\n",
    "            except:  \n",
    "                continue\n",
    "            with open(os.getcwd() + '/' + speech_path + '/' + filename + '.txt', 'w') as text_file:\n",
    "                text_file.write(text)\n",
    "            meta.append(metadata[i])\n",
    "\n",
    "            \n",
    "        \n",
    "    with open(\"META\" + str(cand_dict[cand]['last']) + str(cand_dict[cand]['start'])[2:4] + '.csv', 'w') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)   \n",
    "        #write header\n",
    "        #csvwriter.wrtie\n",
    "    # writing the data rows  \n",
    "        csvwriter.writerows(meta) \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"date-display-single\" content=\"2020-12-23T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 23, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-23T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 23, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-23T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 23, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-23T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 23, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-23T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 23, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-24T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 24, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-25T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 25, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-25T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 25, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-26T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 26, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-26T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 26, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-27T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 27, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-27T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 27, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-27T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 27, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-27T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 27, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-27T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 27, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-27T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 27, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-28T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 28, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-28T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 28, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-28T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 28, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-28T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 28, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-29T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 29, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-30T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 30, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-30T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 30, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-30T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 30, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-30T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 30, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-30T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 30, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-31T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 31, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-31T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 31, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-31T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 31, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-31T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 31, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-31T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 31, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-31T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 31, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-31T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 31, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2020-12-31T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">December 31, 2020</span>,\n",
       " <span class=\"date-display-single\" content=\"2021-01-01T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">January 01, 2021</span>,\n",
       " <span class=\"date-display-single\" content=\"1946-06-14T00:00:00+00:00\" datatype=\"xsd:dateTime\" property=\"dc:date\">June 14, 1946</span>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
