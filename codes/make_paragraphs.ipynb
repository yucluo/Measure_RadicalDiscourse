{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract paragraphs, combine short paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yuchenluo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCSB New Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"text\",\"candidate\", \"term\", \"title\", \"comp\"]\n",
    "rows = []\n",
    "for root, dirs, files, in os.walk('/Users/yuchenluo/Desktop/Measure_RadicalDiscourse'):\n",
    "    for file in files:\n",
    "        if file.endswith('txt'):\n",
    "            speech = open(os.path.join(root, file), \"r\").read()\n",
    "            #speech = f.read()\n",
    "            #get meta data of the speech\n",
    "            cand = re.sub(\"-speech.*\", \"\", file)\n",
    "            term = re.search(\"speech-(.*)-\", file).group(1)[0:4]\n",
    "            title = re.search(\"speech-(.*).txt\", file).group(1)\n",
    "            pars = speech.split('\\n')\n",
    "            pars = [i for i in pars if i] #remove empty strings\n",
    "            pars = [re.sub(\" \\[[^()]*\\]\", \"\", par) for par in pars] #remove strings inside brackets\n",
    "            # loop through all paragraphs inside each speech \n",
    "            i = 0    \n",
    "            while i < len(pars):\n",
    "                n_sent = len(sent_tokenize(pars[i]))\n",
    "                if n_sent >2:\n",
    "                    row = [pars[i], cand, term, title, False]\n",
    "                    rows.append(row)\n",
    "                    i += 1\n",
    "                elif i < len(pars) - 1:\n",
    "                    row = [pars[i] + \" \" + pars[i +1], cand, term, title, True]\n",
    "                    i += 2\n",
    "                    if len(sent_tokenize(row[0])) < 3 and i < len(pars):\n",
    "                        row_2 = [row[0] + \" \" + pars[i], cand, term, title, True]\n",
    "                        i += 1\n",
    "                        rows.append(row_2)\n",
    "                    else: \n",
    "                        rows.append(row)\n",
    "                elif i == (len(pars) - 1): \n",
    "                    row = [pars[i], cand, term, title, False]\n",
    "                    rows.append(row)\n",
    "                    i += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"paragraphs.csv\", 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)   \n",
    "    writer.writerow(col_names)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCSB Old Loop (Ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"text\",\"candidate\", \"term\", \"title\", \"comp\"]\n",
    "rows = []\n",
    "tracker_df = pd.DataFrame(columns = [\"Speech_id\",'text','tracker'])\n",
    "\n",
    "for root, dirs, files, in os.walk('/Users/yuchenluo/Desktop/Measure_RadicalDiscourse'):\n",
    "    for file in files:\n",
    "        if file.endswith('txt'):\n",
    "            speech = open(os.path.join(root, file), \"r\").read()\n",
    "            #speech = f.read()\n",
    "            #get meta data of the speech\n",
    "            cand = re.sub(\"-speech.*\", \"\", file)\n",
    "            term = re.search(\"speech-(.*)-\", file).group(1)[0:4]\n",
    "            title = re.search(\"speech-(.*).txt\", file).group(1)\n",
    "            pars = speech.split('\\n')\n",
    "            pars = [i for i in pars if i] #remove empty strings\n",
    "            pars = [re.sub(\" \\[[^()]*\\]\", \"\", par) for par in pars] #remove strings inside brackets\n",
    "            ##################################################\n",
    "            # Define a pars tracker checking what objects have been used\n",
    "            pars_tracker = pd.DataFrame(columns = [\"Speech_id\",'text','tracker'])\n",
    "            pars_tracker['text'] = pars\n",
    "            pars_tracker[\"Speech_id\"] = title\n",
    "            # loop through all paragraphs inside each speech \n",
    "            i = 0    \n",
    "            while i < (len(pars) - 1):\n",
    "                n_sent = len(sent_tokenize(pars[i]))\n",
    "                if n_sent >2:\n",
    "                    row = [pars[i], cand, term, title, False]\n",
    "                    pars_tracker[\"tracker\"][i] = \"used\"\n",
    "                    rows.append(row)\n",
    "                    i += 1\n",
    "                elif i < len(pars) - 1:\n",
    "                    row = [pars[i] + \" \" + pars[i +1], cand, term, title, True]\n",
    "                    pars_tracker[\"tracker\"][i] = \"used\"\n",
    "                    pars_tracker[\"tracker\"][i+1] = \"used\"\n",
    "                    i += 2\n",
    "                    if len(sent_tokenize(row[0])) < 3 and i < len(pars) - 1:\n",
    "                        row_2 = [row[0] + \" \" + pars[i], cand, term, title, True]\n",
    "                        pars_tracker[\"tracker\"][i] = \"used\"\n",
    "                        i += 1\n",
    "                        rows.append(row_2)\n",
    "                    else: \n",
    "                        rows.append(row)\n",
    "                else: \n",
    "                    row = [pars[i - 1] + \" \" + pars[i], cand, term, title, True]\n",
    "                    print(i)\n",
    "                    rows.pop()\n",
    "                    rows.append(row)\n",
    "            tracker_df = tracker_df.append(pars_tracker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD par id\n",
    "tracker_df = tracker_df[tracker_df['tracker'] != \"used\"]\n",
    "tracker_df['par_id'] = \"None\"\n",
    "for speech_id in tracker_df['Speech_id']:\n",
    "    tracker_df.loc[tracker_df['Speech_id'] == speech_id,'par_id'] = list(range(998, 998 + len(tracker_df[tracker_df['Speech_id'] == speech_id])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([998, 999], dtype=object)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker_df[tracker_df['tracker'] != \"used\"].to_csv('unused_UCSB.csv')\n",
    "tracker_df['par_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"text\",\"candidate\", \"term\", \"title\", \"comp\"]\n",
    "with open(\"paragraphs_old.csv\", 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)   \n",
    "    writer.writerow(col_names)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs_new = pd.read_csv(\"paragraphs.csv\")\n",
    "paragraphs_old = pd.read_csv(\"paragraphs_old.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the old and the new one\n",
    "df = pd.merge(paragraphs_old, paragraphs_new, on=\"text\", how='outer', indicator=True).query(\"_merge != 'both'\").drop('_merge', axis=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(paragraphs_new))\n",
    "print(len(paragraphs_old))\n",
    "df.to_csv(\"paragraphs_dropped.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat the process for Annenberg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "annen_meta = pd.read_csv(\"/Users/yuchenluo/Desktop/Measure_RadicalDiscourse/annenberg_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "root = \"/Users/yuchenluo/Desktop/Measure_RadicalDiscourse/Annenberg-data\" \n",
    "col_names = [\"Speech_id\",\"text\",\"party\", \"term\", \"comp\"] \n",
    "rows = [] \n",
    "\n",
    "for file in os.listdir('/Users/yuchenluo/Desktop/Measure_RadicalDiscourse/Annenberg-data'): \n",
    "    if file.endswith('txt'): \n",
    "        speech = open(os.path.join(root, file), \"r\").read() \n",
    "        #get meta data of the speech \n",
    "        id_speech = re.search('File_(.*).txt', file).group(1) \n",
    "        party = annen_meta[annen_meta['id_speech'] == float(id_speech)]['party'].iloc[0] \n",
    "        term = annen_meta[annen_meta['id_speech'] == float(id_speech)]['year'].iloc[0] \n",
    "        pars = speech.split('\\n\\n') \n",
    "        Type = annen_meta[annen_meta['id_speech'] == float(id_speech)]['type'].iloc[0] \n",
    "        if Type == 'Speeches': #only keep speeches \n",
    "        # the last paragraph is not part of body text\n",
    "            pars = [i for i in pars if i] #remove empty strings \n",
    "            pars = [re.sub(\" \\[[^()]*\\]\", \"\", par) for par in pars] #remove strings inside brackets \n",
    "            pars = [re.sub(\"\\t\", \"\",par) for par in pars]\n",
    "            pars = [re.sub(\"\\n\", \"\",par) for par in pars] # remove \\t and \\n\n",
    "            # loop through all paragraphs inside each speech  \n",
    "            i = 0    \n",
    "            while i < len(pars):\n",
    "                n_sent = len(sent_tokenize(pars[i]))\n",
    "                if n_sent >2:\n",
    "                    row = [id_speech, pars[i], party, term, False]\n",
    "                    pars_tracker[\"tracker\"][i] = \"used\"\n",
    "                    rows.append(row)\n",
    "                    i += 1\n",
    "                elif i < len(pars) - 1:\n",
    "                    row = [id_speech, pars[i] + \" \" + pars[i +1], party, term, True]\n",
    "                    pars_tracker[\"tracker\"][i] = \"used\"\n",
    "                    pars_tracker[\"tracker\"][i+1] = \"used\"\n",
    "                    i += 2\n",
    "                    if len(sent_tokenize(row[1])) < 3 and i < len(pars):\n",
    "                        row_2 = [id_speech, row[1] + \" \" + pars[i], party, term,True]\n",
    "                        pars_tracker[\"tracker\"][i] = \"used\"\n",
    "                        i += 1\n",
    "                        rows.append(row_2)\n",
    "                    else: \n",
    "                        rows.append(row)\n",
    "                elif i == (len(pars) - 1): \n",
    "                    row = [id_speech,rows[-1][1] + \" \" + pars[i], party, term, True]\n",
    "                    rows.pop()\n",
    "                    rows.append(row)\n",
    "                    i += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"paragraphs_annenberg.csv\", 'w') as csvfile: \n",
    "    writer = csv.writer(csvfile)    \n",
    "    writer.writerow(col_names) \n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Loop (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/yuchenluo/Desktop/Measure_RadicalDiscourse/Annenberg-data\" \n",
    "col_names = [\"Speech_id\",\"text\",\"party\", \"term\", \"comp\"] \n",
    "rows = [] \n",
    "tracker_df = pd.DataFrame(columns = [\"Speech_id\",'text','tracker'])\n",
    "\n",
    "for file in os.listdir('/Users/yuchenluo/Desktop/Measure_RadicalDiscourse/Annenberg-data'): \n",
    "    if file.endswith('txt'): \n",
    "        speech = open(os.path.join(root, file), \"r\").read() \n",
    "        #get meta data of the speech \n",
    "        id_speech = re.search('File_(.*).txt', file).group(1) \n",
    "        party = annen_meta[annen_meta['id_speech'] == float(id_speech)]['party'].iloc[0] \n",
    "        term = annen_meta[annen_meta['id_speech'] == float(id_speech)]['year'].iloc[0] \n",
    "        pars = speech.split('\\n\\n') \n",
    "        Type = annen_meta[annen_meta['id_speech'] == float(id_speech)]['type'].iloc[0] \n",
    "        if Type == 'Speeches': #only keep speeches \n",
    "            pars = [i for i in pars if i] #remove empty strings \n",
    "            pars = [re.sub(\" \\[[^()]*\\]\", \"\", par) for par in pars] #remove strings inside brackets \n",
    "            pars = [re.sub(\"\\t\", \"\",par) for par in pars]\n",
    "            pars = [re.sub(\"\\n\", \"\",par) for par in pars] # remove \\t and \\n\n",
    "            ##################################################\n",
    "            # Define a pars tracker checking what objects have been used\n",
    "            pars_tracker = pd.DataFrame(columns = [\"Speech_id\",'text','tracker'])\n",
    "            pars_tracker['text'] = pars\n",
    "            pars_tracker[\"Speech_id\"] = id_speech\n",
    "            # the last paragraph is not part of body text\n",
    "            del pars[-1] \n",
    "            # loop through all paragraphs inside each speech  \n",
    "            i = 0     \n",
    "            while i < (len(pars) - 1): \n",
    "                n_sent = len(sent_tokenize(pars[i])) \n",
    "                if n_sent >2: \n",
    "                    row = [id_speech, pars[i], party, term, False] \n",
    "                    pars_tracker[\"tracker\"][i] = \"used\"\n",
    "                    rows.append(row) \n",
    "                    i += 1 \n",
    "                elif i < len(pars) - 1: \n",
    "                    row = [id_speech, pars[i] + \" \" + pars[i +1], party, term, True] \n",
    "                    #Set pars tracker\n",
    "                    pars_tracker[\"tracker\"][i] = \"used\"\n",
    "                    pars_tracker[\"tracker\"][i+1] = \"used\"\n",
    "                    i += 2 \n",
    "                    if len(sent_tokenize(row[1])) < 3 and i < len(pars) - 1: \n",
    "                        row_2 = [id_speech, row[1] + \" \" + pars[i], party, term, True] \n",
    "                        pars_tracker[\"tracker\"][i] = \"used\"\n",
    "                        i += 1 \n",
    "                        rows.append(row_2) \n",
    "                    else:  \n",
    "                        rows.append(row) \n",
    "                else:  \n",
    "                    row = [id_speech, pars[i - 1] + \" \" + pars[i], party, term, True] \n",
    "                    rows.pop() \n",
    "                    rows.append(row)\n",
    "            tracker_df = tracker_df.append(pars_tracker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"used_pars.csv\", 'w') as csvfile: \n",
    "    writer = csv.writer(csvfile)    \n",
    "    writer.writerow([\"text\",\"used\"]) \n",
    "    writer.writerows(pars_tracker_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracker_df[tracker_df['tracker'] != \"used\"].to_csv('used_tracker.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"paragraphs_annenberg_old.csv\", 'w') as csvfile: \n",
    "    writer = csv.writer(csvfile)    \n",
    "    writer.writerow(col_names) \n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs_new = pd.read_csv(\"paragraphs_annenberg.csv\")\n",
    "paragraphs_old = pd.read_csv(\"paragraphs_annenberg_old.csv\")\n",
    "# compare the old and the new one\n",
    "df = pd.merge(paragraphs_old, paragraphs_new, on=\"text\", how='outer', indicator=True).query(\"_merge != 'both'\").drop('_merge', axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge the dropped paragraphs, too (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cleaned dropped paragraphs\n",
    "unused_annenberg_cleaned = pd.read_csv(\"unused_annenberg_cleaned.csv\")\n",
    "unused_UCSB = pd.read_csv(\"unused_UCSB.csv\")\n",
    "\n",
    "all_unused = unused_annenberg_cleaned[[\"Speech_id\", \"text\", \"par_id\"]].append(unused_UCSB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speech_id</th>\n",
       "      <th>text</th>\n",
       "      <th>par_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2682</td>\n",
       "      <td>But we can turn those policies around, reinvig...</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2682</td>\n",
       "      <td>And we should start by repealing the social se...</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2696</td>\n",
       "      <td>I would like to have your support.</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>906</td>\n",
       "      <td>A democracy is a live society--and growth is t...</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>906</td>\n",
       "      <td>You will hear a lot about the need for a chang...</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>2004-09-16-general-conference-las</td>\n",
       "      <td>Thank you, God bless you, and God bless America.</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>2000-10-30-remarks-muskegon-michigan</td>\n",
       "      <td>Thank you — God bless you — and God bless Amer...</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>2000-09-29-chevy-chase-maryland</td>\n",
       "      <td>Thank you — God bless you — and let's win this...</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>2000-11-01-remarks-kissimmee-florida</td>\n",
       "      <td>Thank you — God bless you — and let's win in F...</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>2000-08-17-national-convention-los</td>\n",
       "      <td>Thank you. God bless you. God bless America.</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3546 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Speech_id  \\\n",
       "0                                    2682   \n",
       "1                                    2682   \n",
       "2                                    2696   \n",
       "3                                     906   \n",
       "4                                     906   \n",
       "..                                    ...   \n",
       "346     2004-09-16-general-conference-las   \n",
       "347  2000-10-30-remarks-muskegon-michigan   \n",
       "348       2000-09-29-chevy-chase-maryland   \n",
       "349  2000-11-01-remarks-kissimmee-florida   \n",
       "350    2000-08-17-national-convention-los   \n",
       "\n",
       "                                                  text  par_id  \n",
       "0    But we can turn those policies around, reinvig...     998  \n",
       "1    And we should start by repealing the social se...     999  \n",
       "2                  I would like to have your support.      998  \n",
       "3    A democracy is a live society--and growth is t...     998  \n",
       "4    You will hear a lot about the need for a chang...     999  \n",
       "..                                                 ...     ...  \n",
       "346   Thank you, God bless you, and God bless America.     998  \n",
       "347  Thank you — God bless you — and God bless Amer...     998  \n",
       "348  Thank you — God bless you — and let's win this...     998  \n",
       "349  Thank you — God bless you — and let's win in F...     998  \n",
       "350       Thank you. God bless you. God bless America.     998  \n",
       "\n",
       "[3546 rows x 3 columns]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"Speech_id\",\"text\",\"par_id\"] \n",
    "rows = [] \n",
    "\n",
    "for speech in all_unused['Speech_id'].unique():\n",
    "    pars = all_unused[all_unused['Speech_id'] == speech]\n",
    "    if len(pars) == 1:\n",
    "        row = [speech, pars['text'].iloc[0], 998] \n",
    "        rows.append(row)\n",
    "    if len(pars) >1:\n",
    "        n_sent = len(sent_tokenize(pars['text'].iloc[0])) \n",
    "        if n_sent >2: \n",
    "            row = [speech, pars['text'].iloc[0], 998] \n",
    "            rows.append(row) \n",
    "            row2 = [speech, pars['text'].iloc[1], 999] \n",
    "            rows.append(row2)\n",
    "        else: \n",
    "            row = [speech, pars[\"text\"].iloc[0] + \" \" + pars[\"text\"].iloc[1], 998] \n",
    "            rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_unused_merged.csv\", 'w') as csvfile: \n",
    "    writer = csv.writer(csvfile)    \n",
    "    writer.writerow(col_names) \n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # group by speech and aggregate         \n",
    "# all_unused = all_unused.astype(str).groupby(all_unused.Speech_id, as_index=True).agg(' '.join)\n",
    "# all_unused['par_id'] = 998 # reset par_id because we don't want those concatenated\n",
    "# all_unused.to_csv(\"all_unused_merged.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to get the speech meta data \n",
    "# all_pars = pd.read_csv('20201115_all_paragraphs.csv')\n",
    "all_unused = pd.read_csv(\"all_unused_merged.csv\")\n",
    "all_unused = all_unused.merge(all_pars[[\"Speech_id\",\"party\", \"term\"]].drop_duplicates(), how = \"left\", on = \"Speech_id\")\n",
    "\n",
    "all_unused.to_csv(\"all_unused_merged.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bind the dropped ones to the main file \n",
    "all_pars_added = all_pars[[\"Speech_id\",\"party\", \"term\", \"text\",\"par_id\"]].append(all_unused)\n",
    "# check if there are duplicates\n",
    "all_pars_added.duplicated(subset = ['Speech_id', \"par_id\"]).unique()\n",
    "# write to file\n",
    "all_pars_added.to_csv(\"20210329_all_paragraphs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([998, 999])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_unused.par_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine UCSB data and Annenberg data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ucsb = pd.read_csv('paragraphs.csv')\n",
    "annenberg = pd.read_csv('paragraphs_annenberg.csv',skipinitialspace=True)\n",
    "\n",
    "# remove \\n and \\t in annenberg data \n",
    "annenberg['text'] = annenberg['text'].replace(r'\\n',' ', regex=True) \n",
    "annenberg['text'] = annenberg['text'].replace(r'\\t',' ', regex=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "# create a party variable for ucsb data to match the annenberg data\n",
    "dems = ['obama', 'gore-jr', 'clinton','kerry']\n",
    "ucsb['party'] = ['dem' if x in dems else 'rep' for x in ucsb['candidate']] \n",
    "\n",
    "# match columns\n",
    "ucsb_matched = ucsb[['title', 'text', 'party', 'term', 'comp']]\n",
    "ucsb_matched.rename(columns = {'title':'Speech_id'}, inplace = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = annenberg.append(ucsb_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add paragraph id\n",
    "all_dt = pd.DataFrame(columns = ['Speech_id', 'text', 'party', 'term', 'comp', 'par_id'])\n",
    "current_id = all_data['Speech_id'].iloc[0]\n",
    "par_id = 0\n",
    "for index, row in all_data.iterrows():\n",
    "    speech_id = row['Speech_id']\n",
    "    par_id += 1\n",
    "    if speech_id != current_id:\n",
    "        current_id = speech_id\n",
    "        par_id = 0\n",
    "    new_row = row\n",
    "    new_row['par_id'] = par_id\n",
    "    all_dt = all_dt.append(new_row)\n",
    "#     print(new_row)\n",
    "#     speech = all_data[all_data['Speech_id'] == sp_id]\n",
    "#     for i in range(len(speech)):\n",
    "#         par = speech.loc[i]\n",
    "#         par['par_id'] = i + 1\n",
    "#         #all_dt.append(par)\n",
    "#         print(par)\n",
    "#     for ind in speech.index: \n",
    "#         i = 1\n",
    "#         speech['par_id'][ind] = i\n",
    "#         i += 1\n",
    "#         print(speech)\n",
    "#     for index, row in speech.iterrows(): \n",
    "#         i = 1\n",
    "#         row['par_id'] = i\n",
    "#         i += 1\n",
    "#         print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('all_paragraphs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample the data (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(11)\n",
    "sample = all_data.sample(n = 1000)\n",
    "sample1 = sample[0:500]\n",
    "sample2 = sample[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1.to_csv('yuchen_sample.csv')\n",
    "sample2.to_csv('bart_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dt.to_csv('NEW_all_paragraphs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.index = range(0,len(all_data))\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Speech_id</th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "      <th>term</th>\n",
       "      <th>comp</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>populist_old_keywords</th>\n",
       "      <th>par_id</th>\n",
       "      <th>total_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15777</td>\n",
       "      <td>2192</td>\n",
       "      <td>The fact of the matter is that we find in the ...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1968</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2192_nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8283</td>\n",
       "      <td>1987</td>\n",
       "      <td>The first thing you do Tuesday morning is get ...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1964</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1987_nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50267</td>\n",
       "      <td>3156</td>\n",
       "      <td>Governor Clinton is talking about \"Well, we re...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1992</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3156_nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12341</td>\n",
       "      <td>1402</td>\n",
       "      <td>In the meantime, wages have been raised and th...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1956</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1402_nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44383</td>\n",
       "      <td>3226</td>\n",
       "      <td>And when people need it, they're smart enough ...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1996</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3226_nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>495</td>\n",
       "      <td>2004-09-07-discussion-sedalia-missouri</td>\n",
       "      <td>The third lesson is, is that we must deal with...</td>\n",
       "      <td>rep</td>\n",
       "      <td>2004</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2004-09-07-discussion-sedalia-missouri_120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>496</td>\n",
       "      <td>3171</td>\n",
       "      <td>So, here we go. Governor Clinton--I honestly b...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1992</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3171_3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>497</td>\n",
       "      <td>1829</td>\n",
       "      <td>This is not the time to go into it in detail, ...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1960</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1829_6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>498</td>\n",
       "      <td>2090</td>\n",
       "      <td>My only prayer is that I will have the strengt...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1968</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2090_14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>499</td>\n",
       "      <td>958</td>\n",
       "      <td>From that day onward, the swelling menace of d...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1952</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11.0</td>\n",
       "      <td>958_11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                               Speech_id  \\\n",
       "0         15777                                    2192   \n",
       "1          8283                                    1987   \n",
       "2         50267                                    3156   \n",
       "3         12341                                    1402   \n",
       "4         44383                                    3226   \n",
       "..          ...                                     ...   \n",
       "995         495  2004-09-07-discussion-sedalia-missouri   \n",
       "996         496                                    3171   \n",
       "997         497                                    1829   \n",
       "998         498                                    2090   \n",
       "999         499                                     958   \n",
       "\n",
       "                                                  text party  term   comp  \\\n",
       "0    The fact of the matter is that we find in the ...   rep  1968   True   \n",
       "1    The first thing you do Tuesday morning is get ...   dem  1964  False   \n",
       "2    Governor Clinton is talking about \"Well, we re...   rep  1992  False   \n",
       "3    In the meantime, wages have been raised and th...   rep  1956  False   \n",
       "4    And when people need it, they're smart enough ...   dem  1996  False   \n",
       "..                                                 ...   ...   ...    ...   \n",
       "995  The third lesson is, is that we must deal with...   rep  2004  False   \n",
       "996  So, here we go. Governor Clinton--I honestly b...   rep  1992  False   \n",
       "997  This is not the time to go into it in detail, ...   rep  1960   True   \n",
       "998  My only prayer is that I will have the strengt...   dem  1968  False   \n",
       "999  From that day onward, the swelling menace of d...   dem  1952  False   \n",
       "\n",
       "     Unnamed: 0.1 populist_old_keywords  par_id  \\\n",
       "0             NaN                   NaN     NaN   \n",
       "1             NaN                   NaN     NaN   \n",
       "2             NaN                   NaN     NaN   \n",
       "3             NaN                   NaN     NaN   \n",
       "4             NaN                   NaN     NaN   \n",
       "..            ...                   ...     ...   \n",
       "995           NaN                  True   120.0   \n",
       "996           NaN                  True     3.0   \n",
       "997           NaN                  True     6.0   \n",
       "998           NaN                  True    14.0   \n",
       "999           NaN                  True    11.0   \n",
       "\n",
       "                                         total_id  \n",
       "0                                        2192_nan  \n",
       "1                                        1987_nan  \n",
       "2                                        3156_nan  \n",
       "3                                        1402_nan  \n",
       "4                                        3226_nan  \n",
       "..                                            ...  \n",
       "995  2004-09-07-discussion-sedalia-missouri_120.0  \n",
       "996                                      3171_3.0  \n",
       "997                                      1829_6.0  \n",
       "998                                     2090_14.0  \n",
       "999                                      958_11.0  \n",
       "\n",
       "[2500 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dt = pd.read_csv('20201115_all_paragraphs.csv')\n",
    "#print(len(all_dt))\n",
    "sample1 = pd.read_csv('yuchen_sample.csv')\n",
    "sample2 = pd.read_csv('bart_sample.csv')\n",
    "sample3 = pd.read_csv('yuchen_2nd_sample.csv')\n",
    "sample4 = pd.read_csv('bart_2nd_sample.csv')\n",
    "sample5 = pd.read_csv('oscar_sample.csv')\n",
    "\n",
    "sample = sample1.append(sample2.append(sample3.append(sample4.append(sample5,ignore_index=True))))\n",
    "sample['total_id'] = sample['Speech_id'].astype(str)  + '_' + sample['par_id'].astype(str) \n",
    "# all_dt['total_id'] = all_dt['Speech_id'].astype(str)  + '_' + all_dt['par_id'].astype(str) \n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Speech_id</th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "      <th>term</th>\n",
       "      <th>comp</th>\n",
       "      <th>populist_old_keywords</th>\n",
       "      <th>par_id</th>\n",
       "      <th>total_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2682</td>\n",
       "      <td>When we start talking about the economy, it's ...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1980</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2682_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2682</td>\n",
       "      <td>It's no secret which groups are hit the hardes...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1980</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2682_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2682</td>\n",
       "      <td>How can our elderly who have worked so hard to...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1980</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2682_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2682</td>\n",
       "      <td>I believe that social security is one of this ...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1980</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2682_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2682</td>\n",
       "      <td>In contrast, I am committed to an economic pro...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1980</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2682_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71822</th>\n",
       "      <td>72341</td>\n",
       "      <td>2000-08-17-national-convention-los</td>\n",
       "      <td>And I ask all of you, my fellow citizens, from...</td>\n",
       "      <td>dem</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>84</td>\n",
       "      <td>2000-08-17-national-convention-los_84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71823</th>\n",
       "      <td>72342</td>\n",
       "      <td>2000-08-17-national-convention-los</td>\n",
       "      <td>I know my own imperfections. For example, I kn...</td>\n",
       "      <td>dem</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>85</td>\n",
       "      <td>2000-08-17-national-convention-los_85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71824</th>\n",
       "      <td>72344</td>\n",
       "      <td>2000-08-17-national-convention-los</td>\n",
       "      <td>Vice President Gore. But the presidency is mor...</td>\n",
       "      <td>dem</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>87</td>\n",
       "      <td>2000-08-17-national-convention-los_87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71825</th>\n",
       "      <td>72345</td>\n",
       "      <td>2000-08-17-national-convention-los</td>\n",
       "      <td>There are big choices ahead and our whole futu...</td>\n",
       "      <td>dem</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>88</td>\n",
       "      <td>2000-08-17-national-convention-los_88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71826</th>\n",
       "      <td>72346</td>\n",
       "      <td>2000-08-17-national-convention-los</td>\n",
       "      <td>If we allow ourselves to believe without reser...</td>\n",
       "      <td>dem</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>89</td>\n",
       "      <td>2000-08-17-national-convention-los_89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71827 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                           Speech_id  \\\n",
       "0               0                                2682   \n",
       "1               1                                2682   \n",
       "2               2                                2682   \n",
       "3               3                                2682   \n",
       "4               4                                2682   \n",
       "...           ...                                 ...   \n",
       "71822       72341  2000-08-17-national-convention-los   \n",
       "71823       72342  2000-08-17-national-convention-los   \n",
       "71824       72344  2000-08-17-national-convention-los   \n",
       "71825       72345  2000-08-17-national-convention-los   \n",
       "71826       72346  2000-08-17-national-convention-los   \n",
       "\n",
       "                                                    text party  term   comp  \\\n",
       "0      When we start talking about the economy, it's ...   rep  1980  False   \n",
       "1      It's no secret which groups are hit the hardes...   rep  1980  False   \n",
       "2      How can our elderly who have worked so hard to...   rep  1980   True   \n",
       "3      I believe that social security is one of this ...   rep  1980   True   \n",
       "4      In contrast, I am committed to an economic pro...   rep  1980   True   \n",
       "...                                                  ...   ...   ...    ...   \n",
       "71822  And I ask all of you, my fellow citizens, from...   dem  2000   True   \n",
       "71823  I know my own imperfections. For example, I kn...   dem  2000  False   \n",
       "71824  Vice President Gore. But the presidency is mor...   dem  2000   True   \n",
       "71825  There are big choices ahead and our whole futu...   dem  2000   True   \n",
       "71826  If we allow ourselves to believe without reser...   dem  2000   True   \n",
       "\n",
       "       populist_old_keywords  par_id                               total_id  \n",
       "0                       True       1                                 2682_1  \n",
       "1                      False       2                                 2682_2  \n",
       "2                      False       3                                 2682_3  \n",
       "3                       True       4                                 2682_4  \n",
       "4                      False       5                                 2682_5  \n",
       "...                      ...     ...                                    ...  \n",
       "71822                  False      84  2000-08-17-national-convention-los_84  \n",
       "71823                  False      85  2000-08-17-national-convention-los_85  \n",
       "71824                  False      87  2000-08-17-national-convention-los_87  \n",
       "71825                  False      88  2000-08-17-national-convention-los_88  \n",
       "71826                  False      89  2000-08-17-national-convention-los_89  \n",
       "\n",
       "[71827 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsampled_dt = all_dt[~all_dt['total_id'].isin(sample['total_id'])]\n",
    "unsampled_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Speech_id</th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "      <th>term</th>\n",
       "      <th>comp</th>\n",
       "      <th>populist_old_keywords</th>\n",
       "      <th>par_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2682</td>\n",
       "      <td>When we start talking about the economy, it's ...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1980</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2682</td>\n",
       "      <td>It's no secret which groups are hit the hardes...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1980</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2682</td>\n",
       "      <td>How can our elderly who have worked so hard to...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1980</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2682</td>\n",
       "      <td>I believe that social security is one of this ...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1980</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2682</td>\n",
       "      <td>In contrast, I am committed to an economic pro...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1980</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71857</th>\n",
       "      <td>72341.0</td>\n",
       "      <td>2000-08-17-national-convention-los</td>\n",
       "      <td>And I ask all of you, my fellow citizens, from...</td>\n",
       "      <td>dem</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71858</th>\n",
       "      <td>72342.0</td>\n",
       "      <td>2000-08-17-national-convention-los</td>\n",
       "      <td>I know my own imperfections. For example, I kn...</td>\n",
       "      <td>dem</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71859</th>\n",
       "      <td>72344.0</td>\n",
       "      <td>2000-08-17-national-convention-los</td>\n",
       "      <td>Vice President Gore. But the presidency is mor...</td>\n",
       "      <td>dem</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71860</th>\n",
       "      <td>72345.0</td>\n",
       "      <td>2000-08-17-national-convention-los</td>\n",
       "      <td>There are big choices ahead and our whole futu...</td>\n",
       "      <td>dem</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71861</th>\n",
       "      <td>72346.0</td>\n",
       "      <td>2000-08-17-national-convention-los</td>\n",
       "      <td>If we allow ourselves to believe without reser...</td>\n",
       "      <td>dem</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69516 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                           Speech_id  \\\n",
       "0             0.0                                2682   \n",
       "1             1.0                                2682   \n",
       "2             2.0                                2682   \n",
       "3             3.0                                2682   \n",
       "4             4.0                                2682   \n",
       "...           ...                                 ...   \n",
       "71857     72341.0  2000-08-17-national-convention-los   \n",
       "71858     72342.0  2000-08-17-national-convention-los   \n",
       "71859     72344.0  2000-08-17-national-convention-los   \n",
       "71860     72345.0  2000-08-17-national-convention-los   \n",
       "71861     72346.0  2000-08-17-national-convention-los   \n",
       "\n",
       "                                                    text party  term   comp  \\\n",
       "0      When we start talking about the economy, it's ...   rep  1980  False   \n",
       "1      It's no secret which groups are hit the hardes...   rep  1980  False   \n",
       "2      How can our elderly who have worked so hard to...   rep  1980   True   \n",
       "3      I believe that social security is one of this ...   rep  1980   True   \n",
       "4      In contrast, I am committed to an economic pro...   rep  1980   True   \n",
       "...                                                  ...   ...   ...    ...   \n",
       "71857  And I ask all of you, my fellow citizens, from...   dem  2000   True   \n",
       "71858  I know my own imperfections. For example, I kn...   dem  2000  False   \n",
       "71859  Vice President Gore. But the presidency is mor...   dem  2000   True   \n",
       "71860  There are big choices ahead and our whole futu...   dem  2000   True   \n",
       "71861  If we allow ourselves to believe without reser...   dem  2000   True   \n",
       "\n",
       "      populist_old_keywords  par_id  \n",
       "0                      True     1.0  \n",
       "1                     False     2.0  \n",
       "2                     False     3.0  \n",
       "3                      True     4.0  \n",
       "4                     False     5.0  \n",
       "...                     ...     ...  \n",
       "71857                 False    84.0  \n",
       "71858                 False    85.0  \n",
       "71859                 False    87.0  \n",
       "71860                 False    88.0  \n",
       "71861                 False    89.0  \n",
       "\n",
       "[69516 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop paragraphs already sampled\n",
    "new_dat = (pd.merge(all_dt, sample[['Speech_id', 'text', 'party', 'term', 'comp']], indicator=True, how='outer')\n",
    "         .query('_merge==\"left_only\"')\n",
    "         .drop('_merge', axis=1))\n",
    "\n",
    "new_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge and clean up new dat \n",
    "all_dt = pd.read_csv('20201110_all_paragraphs.csv')\n",
    "merged = new_dat.merge(all_dt, how = \"left\", on = \"text\")\n",
    "merged = merged[merged['Speech_id_x'] == merged['Speech_id_y']] \n",
    "del merged['Speech_id_y']\n",
    "\n",
    "merged = merged.drop_duplicates(subset = [\"Speech_id_x\", \"par_id\"])\n",
    "\n",
    "\n",
    "del merged[\"Unnamed: 0_x\"]\n",
    "del merged[\"Unnamed: 0_y\"]\n",
    "del merged[\"party_y\"]\n",
    "del merged[\"term_y\"]\n",
    "del merged[\"comp_y\"]\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "merged = merged[merged['text'].notna()] #remove na \n",
    "audience = merged[merged['text'].str.contains('Audience')] # check where the audience reaction is \n",
    "audience = audience[audience['text'].str.split().str.len()<13] # most audience reactions are short \n",
    "merged = (pd.merge(merged, audience, indicator=True, how='outer')\n",
    "         .query('_merge==\"left_only\"')\n",
    "         .drop('_merge', axis=1))\n",
    "\n",
    "merged.rename(columns = {'Speech_id_x':'Speech_id', 'party_x':\"party\", \"term_x\":\"term\", \"comp_x\":\"comp\", \"populist_old_keywords_x\":\"populist_old_keywords\"}, inplace = True) \n",
    "del merged['populist_old_keywords_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE\n",
    "import random\n",
    "import pandas as pd\n",
    "# merged = pd.read_csv('20201115_all_paragraphs.csv')\n",
    "random.seed(11)\n",
    "new_sample = new_dat.sample(n = 250)\n",
    "\n",
    "# # first 500 completely random\n",
    "# sample1 = sample[0:500]\n",
    "# # second sample = 250 random + 250 populist keyword == T\n",
    "# sample2_1 = sample[500:750]\n",
    "\n",
    "# sample = sample1.append(sample2_1, ignore_index = True)\n",
    "\n",
    "# # exclude the ones already sampled \n",
    "# new_sample = (pd.merge(merged, sample, indicator=True, how='outer')\n",
    "#          .query('_merge==\"left_only\"')\n",
    "#          .drop('_merge', axis=1))\n",
    "# sample2_2 = new_sample[new_sample['populist_old_keywords'] == True].sample(n = 250)\n",
    "\n",
    "# sample2 = sample2_1.append(sample2_2, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "new_sample['par_id'] = new_sample['par_id'].astype(int)\n",
    "new_sample['total_id'] = new_sample['Speech_id'].astype(str)  + '_' + new_sample['par_id'].astype(str) \n",
    "new_sample = new_sample[[\"total_id\",'Speech_id',\"par_id\", \"text\", \"party\", \"term\", \"comp\", \"populist_old_keywords\"]]\n",
    "#sample1.to_csv('bart_2nd_sample.csv')\n",
    "#sample2.to_csv('yuchen_2nd_sample.csv')\n",
    "new_sample.to_csv('oscar_2nd_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speech_id_x</th>\n",
       "      <th>text</th>\n",
       "      <th>party_x</th>\n",
       "      <th>term_x</th>\n",
       "      <th>comp_x</th>\n",
       "      <th>par_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2133</td>\n",
       "      <td>Mr. Nixon has come to this city and he has brought a message on the date of October 23rd which says the \"U. S. World Lead Lost, Nixon Tells Battle Creek Audience,\" and what did he say?  He said we...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1968</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15470</th>\n",
       "      <td>2804</td>\n",
       "      <td>Well now, it's time for me to go-- [Audience: No!] Yes--oh--have to. But I see so many families here this afternoon, so many fine young people. May I just leave you with one last thought from my h...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1984</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50512</th>\n",
       "      <td>2012-09-27-virginia-beach-virginia</td>\n",
       "      <td>The President. Jim Webb! Audience members. Four more years! Four more years! Four more years!</td>\n",
       "      <td>dem</td>\n",
       "      <td>2012</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50518</th>\n",
       "      <td>2012-09-27-virginia-beach-virginia</td>\n",
       "      <td>Audience members. Yours! The President. No, well, I know some in the crowd may be a little biased, but—[Laughter]—but I also want to speak to the audience who may be seeing this over the television.</td>\n",
       "      <td>dem</td>\n",
       "      <td>2012</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50528</th>\n",
       "      <td>2012-09-27-virginia-beach-virginia</td>\n",
       "      <td>Number one, I want to export more products and I want to outsource fewer jobs. When my opponent said we should just \"let Detroit go bankrupt\"—— Audience members. Boo!</td>\n",
       "      <td>dem</td>\n",
       "      <td>2012</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69728</th>\n",
       "      <td>2016-10-12-pavilion-ocala-florida</td>\n",
       "      <td>And who is going to pay for the wall? Audience: \"Mexico\" 100 percent. They just don't know it yet. They don't know it yet, but 100 percent. They'll pay for the wall.</td>\n",
       "      <td>rep</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71297</th>\n",
       "      <td>2000-08-17-national-convention-los</td>\n",
       "      <td>You know... Audience. Go, Al, go. Go, Al, go. Go, Al, go. Go, Al, go. Go, Al, go.</td>\n",
       "      <td>dem</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71298</th>\n",
       "      <td>2000-08-17-national-convention-los</td>\n",
       "      <td>Vice President Gore. Are you with me? Audience. Go, Al, go. Go, Al, go. Go, Al, go.</td>\n",
       "      <td>dem</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71312</th>\n",
       "      <td>2000-08-17-national-convention-los</td>\n",
       "      <td>And all of this...[applause] Audience. Go, Al, go. Go, Al, go. Go, Al, go. Go, Al, go. Go, Al, go.</td>\n",
       "      <td>dem</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71324</th>\n",
       "      <td>2000-08-17-national-convention-los</td>\n",
       "      <td>I mean that with all my heart. Audience. Go Al, go. Go Al, go. Go Al, go. Go Al, go. Go Al, go.</td>\n",
       "      <td>dem</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Speech_id_x  \\\n",
       "198                                  2133   \n",
       "15470                                2804   \n",
       "50512  2012-09-27-virginia-beach-virginia   \n",
       "50518  2012-09-27-virginia-beach-virginia   \n",
       "50528  2012-09-27-virginia-beach-virginia   \n",
       "...                                   ...   \n",
       "69728   2016-10-12-pavilion-ocala-florida   \n",
       "71297  2000-08-17-national-convention-los   \n",
       "71298  2000-08-17-national-convention-los   \n",
       "71312  2000-08-17-national-convention-los   \n",
       "71324  2000-08-17-national-convention-los   \n",
       "\n",
       "                                                                                                                                                                                                          text  \\\n",
       "198    Mr. Nixon has come to this city and he has brought a message on the date of October 23rd which says the \"U. S. World Lead Lost, Nixon Tells Battle Creek Audience,\" and what did he say?  He said we...   \n",
       "15470  Well now, it's time for me to go-- [Audience: No!] Yes--oh--have to. But I see so many families here this afternoon, so many fine young people. May I just leave you with one last thought from my h...   \n",
       "50512                                                                                                            The President. Jim Webb! Audience members. Four more years! Four more years! Four more years!   \n",
       "50518   Audience members. Yours! The President. No, well, I know some in the crowd may be a little biased, but—[Laughter]—but I also want to speak to the audience who may be seeing this over the television.   \n",
       "50528                                   Number one, I want to export more products and I want to outsource fewer jobs. When my opponent said we should just \"let Detroit go bankrupt\"—— Audience members. Boo!   \n",
       "...                                                                                                                                                                                                        ...   \n",
       "69728                                    And who is going to pay for the wall? Audience: \"Mexico\" 100 percent. They just don't know it yet. They don't know it yet, but 100 percent. They'll pay for the wall.   \n",
       "71297                                                                                                                        You know... Audience. Go, Al, go. Go, Al, go. Go, Al, go. Go, Al, go. Go, Al, go.   \n",
       "71298                                                                                                                      Vice President Gore. Are you with me? Audience. Go, Al, go. Go, Al, go. Go, Al, go.   \n",
       "71312                                                                                                       And all of this...[applause] Audience. Go, Al, go. Go, Al, go. Go, Al, go. Go, Al, go. Go, Al, go.   \n",
       "71324                                                                                                          I mean that with all my heart. Audience. Go Al, go. Go Al, go. Go Al, go. Go Al, go. Go Al, go.   \n",
       "\n",
       "      party_x  term_x  comp_x  par_id  \n",
       "198       dem    1968   False      26  \n",
       "15470     rep    1984    True      26  \n",
       "50512     dem    2012    True       0  \n",
       "50518     dem    2012    True       7  \n",
       "50528     dem    2012    True      18  \n",
       "...       ...     ...     ...     ...  \n",
       "69728     rep    2016    True     116  \n",
       "71297     dem    2000    True      31  \n",
       "71298     dem    2000    True      32  \n",
       "71312     dem    2000    True      48  \n",
       "71324     dem    2000    True      60  \n",
       "\n",
       "[1300 rows x 6 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[merged['text'].str.contains('Audience')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('20201115_all_paragraphs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add paragraph id (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0                                               text  \\\n",
      "0             0  The future is my responsibility and it's yours...   \n",
      "1             1  I ask you to help us make new history and I as...   \n",
      "2             2  But, getting back to the issues before us, I s...   \n",
      "3             3  It used to be in America all the racial issues...   \n",
      "4             4  Mr. Lamb. Yes, it's a legal term. The Presiden...   \n",
      "..          ...                                                ...   \n",
      "492         766  Ten months ago, in a tragic moment, I was call...   \n",
      "493         767  He says he cares about the middle class, but h...   \n",
      "494         768  We have got to have a tough plan to bring heal...   \n",
      "495         769  The constant partisan rancor that stops us fro...   \n",
      "496         770  We began working on an energy policy, which th...   \n",
      "\n",
      "            label   annotated_at                               Speech_id_x  \\\n",
      "0    not populist  11/4/20 15:28                                      2600   \n",
      "1    not populist  11/4/20 15:29                                      2005   \n",
      "2    not populist  11/4/20 15:29                                      1871   \n",
      "3    not populist  11/4/20 15:29                                      3256   \n",
      "4    not populist  11/4/20 15:30    2004-09-07-discussion-sedalia-missouri   \n",
      "..            ...            ...                                       ...   \n",
      "492  not populist  11/13/20 9:49                                      1922   \n",
      "493  not populist  11/13/20 9:49                                      2868   \n",
      "494  not populist  11/13/20 9:49                                      3004   \n",
      "495      populist  11/13/20 9:50  2008-10-01-remarks-independence-missouri   \n",
      "496  not populist  11/13/20 9:50                                      2575   \n",
      "\n",
      "    party_x  term_x  comp_x  par_id_y  \n",
      "0       dem    1980   False       8.0  \n",
      "1       dem    1968    True      27.0  \n",
      "2       rep    1960    True       3.0  \n",
      "3       dem    1996   False       9.0  \n",
      "4       rep    2004    True      47.0  \n",
      "..      ...     ...     ...       ...  \n",
      "492     dem    1964    True      21.0  \n",
      "493     rep    1984   False      14.0  \n",
      "494     dem    1992    True      31.0  \n",
      "495     rep    2008    True      16.0  \n",
      "496     dem    1980   False      11.0  \n",
      "\n",
      "[497 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "bart_sample = pd.read_csv(\"bart_sample.csv\")\n",
    "bart_annot = pd.read_csv(\"annotated_par_populism_bart.csv\")\n",
    "all_dat = pd.read_csv(\"20201115_all_paragraphs.csv\")\n",
    "\n",
    "#print(bart_sample)\n",
    "print(bart_annot)\n",
    "#print(all_dat)\n",
    "\n",
    "#all_dat[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Speech_id_x', 'comp_x', 'party_x', 'term_x', 'par_id_y'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0a1b7d604d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbart_annot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbart_annot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Speech_id_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'par_id_y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'party_x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'term_x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'comp_x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Speech_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'par_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'party'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'term'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'comp'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbart_annot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1552\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m         )\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Speech_id_x', 'comp_x', 'party_x', 'term_x', 'par_id_y'] not in index\""
     ]
    }
   ],
   "source": [
    "bart_annot = bart_annot[['Speech_id_x', 'par_id_y', 'text', 'party_x','term_x','comp_x','label']]\n",
    "\n",
    "cols = ['Speech_id','par_id','text', 'party','term','comp','label']\n",
    " \n",
    "bart_annot.columns = cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Speech_id  par_id  \\\n",
      "0                                        2600     8.0   \n",
      "1                                        2005    27.0   \n",
      "2                                        1871     3.0   \n",
      "3                                        3256     9.0   \n",
      "4      2004-09-07-discussion-sedalia-missouri    47.0   \n",
      "..                                        ...     ...   \n",
      "492                                      1922    21.0   \n",
      "493                                      2868    14.0   \n",
      "494                                      3004    31.0   \n",
      "495  2008-10-01-remarks-independence-missouri    16.0   \n",
      "496                                      2575    11.0   \n",
      "\n",
      "                                                  text party  term   comp  \\\n",
      "0    The future is my responsibility and it's yours...   dem  1980  False   \n",
      "1    I ask you to help us make new history and I as...   dem  1968   True   \n",
      "2    But, getting back to the issues before us, I s...   rep  1960   True   \n",
      "3    It used to be in America all the racial issues...   dem  1996  False   \n",
      "4    Mr. Lamb. Yes, it's a legal term. The Presiden...   rep  2004   True   \n",
      "..                                                 ...   ...   ...    ...   \n",
      "492  Ten months ago, in a tragic moment, I was call...   dem  1964   True   \n",
      "493  He says he cares about the middle class, but h...   rep  1984  False   \n",
      "494  We have got to have a tough plan to bring heal...   dem  1992   True   \n",
      "495  The constant partisan rancor that stops us fro...   rep  2008   True   \n",
      "496  We began working on an energy policy, which th...   dem  1980  False   \n",
      "\n",
      "            label  \n",
      "0    not populist  \n",
      "1    not populist  \n",
      "2    not populist  \n",
      "3    not populist  \n",
      "4    not populist  \n",
      "..            ...  \n",
      "492  not populist  \n",
      "493  not populist  \n",
      "494  not populist  \n",
      "495      populist  \n",
      "496  not populist  \n",
      "\n",
      "[497 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(bart_annot)\n",
    "bart_annot.to_csv(\"bart_annotated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Speech_id</th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "      <th>term</th>\n",
       "      <th>comp</th>\n",
       "      <th>populist_old_keywords</th>\n",
       "      <th>par_id</th>\n",
       "      <th>drawn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2162</td>\n",
       "      <td>But don't worry about that. You know who is in...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1968</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>randomly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-28-manchester-new-hampshire</td>\n",
       "      <td>And these people are seriously corrupt. Terrib...</td>\n",
       "      <td>rep</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "      <td>randomly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1045</td>\n",
       "      <td>We can make our society ever more productive a...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1952</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>randomly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2397</td>\n",
       "      <td>Q. Do you think that Gerald Ford had anything ...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1976</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>randomly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2012-10-05-rally-fairfax-virginia</td>\n",
       "      <td>One of the main reasons record surpluses under...</td>\n",
       "      <td>dem</td>\n",
       "      <td>2012</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>randomly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>2004-09-07-discussion-sedalia-missouri</td>\n",
       "      <td>The third lesson is, is that we must deal with...</td>\n",
       "      <td>rep</td>\n",
       "      <td>2004</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>120</td>\n",
       "      <td>keyword</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>3171</td>\n",
       "      <td>So, here we go. Governor Clinton--I honestly b...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1992</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>keyword</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>1829</td>\n",
       "      <td>This is not the time to go into it in detail, ...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1960</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>keyword</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>2090</td>\n",
       "      <td>My only prayer is that I will have the strengt...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1968</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>keyword</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>958</td>\n",
       "      <td>From that day onward, the swelling menace of d...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1952</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>keyword</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                               Speech_id  \\\n",
       "0             0                                    2162   \n",
       "1             1     2016-10-28-manchester-new-hampshire   \n",
       "2             2                                    1045   \n",
       "3             3                                    2397   \n",
       "4             4       2012-10-05-rally-fairfax-virginia   \n",
       "..          ...                                     ...   \n",
       "495         495  2004-09-07-discussion-sedalia-missouri   \n",
       "496         496                                    3171   \n",
       "497         497                                    1829   \n",
       "498         498                                    2090   \n",
       "499         499                                     958   \n",
       "\n",
       "                                                  text party  term   comp  \\\n",
       "0    But don't worry about that. You know who is in...   rep  1968  False   \n",
       "1    And these people are seriously corrupt. Terrib...   rep  2016   True   \n",
       "2    We can make our society ever more productive a...   dem  1952   True   \n",
       "3    Q. Do you think that Gerald Ford had anything ...   dem  1976   True   \n",
       "4    One of the main reasons record surpluses under...   dem  2012  False   \n",
       "..                                                 ...   ...   ...    ...   \n",
       "495  The third lesson is, is that we must deal with...   rep  2004  False   \n",
       "496  So, here we go. Governor Clinton--I honestly b...   rep  1992  False   \n",
       "497  This is not the time to go into it in detail, ...   rep  1960   True   \n",
       "498  My only prayer is that I will have the strengt...   dem  1968  False   \n",
       "499  From that day onward, the swelling menace of d...   dem  1952  False   \n",
       "\n",
       "     populist_old_keywords  par_id     drawn  \n",
       "0                    False       3  randomly  \n",
       "1                     True      21  randomly  \n",
       "2                    False      13  randomly  \n",
       "3                    False      30  randomly  \n",
       "4                    False       9  randomly  \n",
       "..                     ...     ...       ...  \n",
       "495                   True     120   keyword  \n",
       "496                   True       3   keyword  \n",
       "497                   True       6   keyword  \n",
       "498                   True      14   keyword  \n",
       "499                   True      11   keyword  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### add par_id to Yuchen first sample\n",
    "\n",
    "\n",
    "oscar_sample = pd.read_csv('oscar_sample.csv')\n",
    "\n",
    "\n",
    "oscar_sample['drawn'] = ['randomly'] *250 + ['keyword'] * 250\n",
    "\n",
    "oscar_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Speech_id</th>\n",
       "      <th>par_id</th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "      <th>term</th>\n",
       "      <th>comp</th>\n",
       "      <th>drawn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2192</td>\n",
       "      <td>27</td>\n",
       "      <td>The fact of the matter is that we find in the ...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1968</td>\n",
       "      <td>True</td>\n",
       "      <td>randomly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>25</td>\n",
       "      <td>The first thing you do Tuesday morning is get ...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1964</td>\n",
       "      <td>False</td>\n",
       "      <td>randomly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3156</td>\n",
       "      <td>11</td>\n",
       "      <td>Governor Clinton is talking about \"Well, we re...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1992</td>\n",
       "      <td>False</td>\n",
       "      <td>randomly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1402</td>\n",
       "      <td>18</td>\n",
       "      <td>In the meantime, wages have been raised and th...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1956</td>\n",
       "      <td>False</td>\n",
       "      <td>randomly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3226</td>\n",
       "      <td>41</td>\n",
       "      <td>And when people need it, they're smart enough ...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1996</td>\n",
       "      <td>False</td>\n",
       "      <td>randomly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>490</td>\n",
       "      <td>2004-10-26-dubuque-iowa-0</td>\n",
       "      <td>34</td>\n",
       "      <td>You cannot be pro-doctor and pro-patient and p...</td>\n",
       "      <td>rep</td>\n",
       "      <td>2004</td>\n",
       "      <td>False</td>\n",
       "      <td>randomly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>491</td>\n",
       "      <td>1076</td>\n",
       "      <td>4</td>\n",
       "      <td>We are not only, as I say, a moral countr...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1952</td>\n",
       "      <td>False</td>\n",
       "      <td>randomly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>492</td>\n",
       "      <td>1659</td>\n",
       "      <td>8</td>\n",
       "      <td>The housing--if there is any state in the unio...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1960</td>\n",
       "      <td>False</td>\n",
       "      <td>randomly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>493</td>\n",
       "      <td>2008-11-03-jacksonville-florida-1</td>\n",
       "      <td>31</td>\n",
       "      <td>Don't believe for a second this election is ov...</td>\n",
       "      <td>dem</td>\n",
       "      <td>2008</td>\n",
       "      <td>False</td>\n",
       "      <td>randomly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>494</td>\n",
       "      <td>2004-09-07-discussion-sedalia-missouri</td>\n",
       "      <td>27</td>\n",
       "      <td>And the reason why I thought that was necessar...</td>\n",
       "      <td>rep</td>\n",
       "      <td>2004</td>\n",
       "      <td>False</td>\n",
       "      <td>randomly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                               Speech_id  par_id  \\\n",
       "0             0                                    2192      27   \n",
       "1             1                                    1987      25   \n",
       "2             2                                    3156      11   \n",
       "3             3                                    1402      18   \n",
       "4             4                                    3226      41   \n",
       "..          ...                                     ...     ...   \n",
       "490         490               2004-10-26-dubuque-iowa-0      34   \n",
       "491         491                                    1076       4   \n",
       "492         492                                    1659       8   \n",
       "493         493       2008-11-03-jacksonville-florida-1      31   \n",
       "494         494  2004-09-07-discussion-sedalia-missouri      27   \n",
       "\n",
       "                                                  text party  term   comp  \\\n",
       "0    The fact of the matter is that we find in the ...   rep  1968   True   \n",
       "1    The first thing you do Tuesday morning is get ...   dem  1964  False   \n",
       "2    Governor Clinton is talking about \"Well, we re...   rep  1992  False   \n",
       "3    In the meantime, wages have been raised and th...   rep  1956  False   \n",
       "4    And when people need it, they're smart enough ...   dem  1996  False   \n",
       "..                                                 ...   ...   ...    ...   \n",
       "490  You cannot be pro-doctor and pro-patient and p...   rep  2004  False   \n",
       "491       We are not only, as I say, a moral countr...   dem  1952  False   \n",
       "492  The housing--if there is any state in the unio...   dem  1960  False   \n",
       "493  Don't believe for a second this election is ov...   dem  2008  False   \n",
       "494  And the reason why I thought that was necessar...   rep  2004  False   \n",
       "\n",
       "        drawn  \n",
       "0    randomly  \n",
       "1    randomly  \n",
       "2    randomly  \n",
       "3    randomly  \n",
       "4    randomly  \n",
       "..        ...  \n",
       "490  randomly  \n",
       "491  randomly  \n",
       "492  randomly  \n",
       "493  randomly  \n",
       "494  randomly  \n",
       "\n",
       "[495 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yuchen_sample = yuchen_annot.drop('label', axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove All Caps Tags (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "annenberg = pd.read_csv(\"used_tracker.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#### OBSELETE\n",
    "# for i in range(len(annenberg['text'])):\n",
    "#     s = annenberg['text'][i]\n",
    "#     s = s.translate(str.maketrans('', '', string.punctuation)) #remove punctuations\n",
    "#     all_caps = \"\".join(re.findall(r\"[A-Z]{3,}.*$\", s))# extract caps (start from the end, greedy search for all caps of 3 or more) \n",
    "#     annenberg['text'][i] = re.sub(all_caps, '', s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(annenberg['text'])):\n",
    "    try:\n",
    "        annenberg['text'][i] = re.match(r'^.+?(?=[A-Z]{3,})', annenberg['text'][i]).group()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Drop empties and <3 letters \n",
    "annenberg = annenberg[annenberg[\"text\"].notna()]\n",
    "annenberg[\"length\"]=annenberg[\"text\"].apply(lambda x: len(x))\n",
    "annenberg = annenberg[annenberg[\"length\"]> 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD par id\n",
    "annenberg['par_id'] = \"None\"\n",
    "for speech_id in annenberg['Speech_id']:\n",
    "    annenberg.loc[annenberg['Speech_id'] == speech_id,'par_id'] = list(range(998, 998 + len(annenberg.loc[annenberg['Speech_id'] == speech_id])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "annenberg.to_csv('used_tracker_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(998, 1000)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(998, 998+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Speech_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tracker</th>\n",
       "      <th>length</th>\n",
       "      <th>par_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>2682</td>\n",
       "      <td>But we can turn those policies around, reinvig...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>2682</td>\n",
       "      <td>And we should start by repealing the social se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2696</td>\n",
       "      <td>I would like to have your support.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>906</td>\n",
       "      <td>A democracy is a live society--and growth is t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>503</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>906</td>\n",
       "      <td>You will hear a lot about the need for a chang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>216</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4316</th>\n",
       "      <td>35</td>\n",
       "      <td>1386</td>\n",
       "      <td>We need a Democratic administration in Washing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4318</th>\n",
       "      <td>61</td>\n",
       "      <td>2857</td>\n",
       "      <td>And now I'll just finish by saying something t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>62</td>\n",
       "      <td>2857</td>\n",
       "      <td>Thank you. Thank you all very much. Thank you.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>13</td>\n",
       "      <td>2843</td>\n",
       "      <td>Today we can talk and negotiate in confidence ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4323</th>\n",
       "      <td>14</td>\n",
       "      <td>2843</td>\n",
       "      <td>Until next week, thanks for listening, and God...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3195 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Speech_id  \\\n",
       "0             13       2682   \n",
       "1             14       2682   \n",
       "2             33       2696   \n",
       "5             15        906   \n",
       "6             16        906   \n",
       "...          ...        ...   \n",
       "4316          35       1386   \n",
       "4318          61       2857   \n",
       "4319          62       2857   \n",
       "4322          13       2843   \n",
       "4323          14       2843   \n",
       "\n",
       "                                                   text  tracker  length  \\\n",
       "0     But we can turn those policies around, reinvig...      NaN     103   \n",
       "1     And we should start by repealing the social se...      NaN      73   \n",
       "2                   I would like to have your support.       NaN      35   \n",
       "5     A democracy is a live society--and growth is t...      NaN     503   \n",
       "6     You will hear a lot about the need for a chang...      NaN     216   \n",
       "...                                                 ...      ...     ...   \n",
       "4316  We need a Democratic administration in Washing...      NaN     155   \n",
       "4318  And now I'll just finish by saying something t...      NaN     145   \n",
       "4319     Thank you. Thank you all very much. Thank you.      NaN      46   \n",
       "4322  Today we can talk and negotiate in confidence ...      NaN     184   \n",
       "4323  Until next week, thanks for listening, and God...      NaN      57   \n",
       "\n",
       "     par_id  \n",
       "0       998  \n",
       "1       999  \n",
       "2       998  \n",
       "5       998  \n",
       "6       999  \n",
       "...     ...  \n",
       "4316    998  \n",
       "4318    998  \n",
       "4319    999  \n",
       "4322    998  \n",
       "4323    999  \n",
       "\n",
       "[3195 rows x 6 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(annenberg['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Q&A and Audience Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# load the paragraphs (with 2020)\n",
    "all_paras = pd.read_csv(\"20220115_all_paragraphs_2020_added.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X</th>\n",
       "      <th>Speech_id</th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "      <th>term</th>\n",
       "      <th>comp</th>\n",
       "      <th>populist_old_keywords</th>\n",
       "      <th>par_id</th>\n",
       "      <th>speech_par_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2682</td>\n",
       "      <td>When we start talking about the economy, it's ...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1980</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2682_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2682</td>\n",
       "      <td>It's no secret which groups are hit the hardes...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1980</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2682_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2682</td>\n",
       "      <td>How can our elderly who have worked so hard to...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1980</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2682_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2682</td>\n",
       "      <td>I believe that social security is one of this ...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1980</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2682_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2682</td>\n",
       "      <td>In contrast, I am committed to an economic pro...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1980</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2682_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  X Speech_id                                               text  \\\n",
       "0           1  0      2682  When we start talking about the economy, it's ...   \n",
       "1           2  1      2682  It's no secret which groups are hit the hardes...   \n",
       "2           3  2      2682  How can our elderly who have worked so hard to...   \n",
       "3           4  3      2682  I believe that social security is one of this ...   \n",
       "4           5  4      2682  In contrast, I am committed to an economic pro...   \n",
       "\n",
       "  party  term   comp populist_old_keywords  par_id speech_par_id  \n",
       "0   rep  1980  False                  True       1        2682_1  \n",
       "1   rep  1980  False                 False       2        2682_2  \n",
       "2   rep  1980   True                 False       3        2682_3  \n",
       "3   rep  1980   True                  True       4        2682_4  \n",
       "4   rep  1980   True                 False       5        2682_5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paras.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to get rid of\n",
    "\n",
    "Q&A through Capital word with :\n",
    "\n",
    "Exception for \"Americans:\"\n",
    "\n",
    "Audience: or Audience. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "junk_qa = []\n",
    "for i in range(len(all_paras['text'])):\n",
    "    if re.search('Audience\\.|AUDIENCE\\.|Audience member\\.|Audience Member\\.|Q\\.|QUESTION\\.|Question\\.', all_paras['text'][i]) is not None:\n",
    "        junk_qa.append(all_paras.loc[i])\n",
    "    elif re.search('[A-Z][A-Za-z]*:', all_paras['text'][i]) is not None and re.search(\"Americans:\", all_paras['text'][i]) is None:\n",
    "        junk_qa.append(all_paras.loc[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "junk_qa_df = pd.DataFrame(junk_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "junk_qa_df.to_csv(\"junk_text.csv\")\n",
    "junk_qa_df.iloc[0:1500].to_csv(\"junk_text_1.csv\")\n",
    "junk_qa_df.iloc[1500:2770].to_csv(\"junk_text_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 9), match='Audience.'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search('Audience\\.|AUDIENCE\\.',\"Audience. Thank you, George. Thank you, George. Thank you, George.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "757"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(junk_qa_df['Speech_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2770"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(junk_qa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_paras['text'])):\n",
    "    all_paras['length'][i] = len(all_paras['text'][i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X</th>\n",
       "      <th>Speech_id</th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "      <th>term</th>\n",
       "      <th>comp</th>\n",
       "      <th>populist_old_keywords</th>\n",
       "      <th>par_id</th>\n",
       "      <th>speech_par_id</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>2133</td>\n",
       "      <td>And that choir, or that singing and choral gro...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1968</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2133_1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>180</td>\n",
       "      <td>179</td>\n",
       "      <td>2133</td>\n",
       "      <td>VOICES:  We Want Humphrey! VICE PRESIDENT HUMP...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1968</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2133_3</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>185</td>\n",
       "      <td>184</td>\n",
       "      <td>2133</td>\n",
       "      <td>VOICES:  We want Humphrey!   VICE PRESIDENT HU...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1968</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2133_8</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>186</td>\n",
       "      <td>185</td>\n",
       "      <td>2133</td>\n",
       "      <td>VOICES:  You!  You! VICE PRESIDENT HUMPHREY:  ...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1968</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>2133_9</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>2133</td>\n",
       "      <td>VOICES:  Humphrey!  Humphrey! VICE PRESIDENT H...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1968</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>2133_10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46902</th>\n",
       "      <td>46903</td>\n",
       "      <td>46902</td>\n",
       "      <td>2505</td>\n",
       "      <td>Q. My question for you today, sir, is, how do ...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1976</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>2505_6</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46903</th>\n",
       "      <td>46904</td>\n",
       "      <td>46903</td>\n",
       "      <td>2505</td>\n",
       "      <td>Q. Washington, Oregon, and Montana are three s...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1976</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>2505_7</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46906</th>\n",
       "      <td>46907</td>\n",
       "      <td>46906</td>\n",
       "      <td>2505</td>\n",
       "      <td>Q. First, I commend you on being able to prono...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1976</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>2505_10</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46910</th>\n",
       "      <td>46911</td>\n",
       "      <td>46910</td>\n",
       "      <td>2505</td>\n",
       "      <td>Q. If we can have the burden, we'll take the r...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1976</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>2505_14</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46912</th>\n",
       "      <td>46913</td>\n",
       "      <td>46912</td>\n",
       "      <td>2505</td>\n",
       "      <td>Q. How much time do you spend with radio? Is r...</td>\n",
       "      <td>rep</td>\n",
       "      <td>1976</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>2505_16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      X Speech_id  \\\n",
       "177           178    177      2133   \n",
       "179           180    179      2133   \n",
       "184           185    184      2133   \n",
       "185           186    185      2133   \n",
       "186           187    186      2133   \n",
       "...           ...    ...       ...   \n",
       "46902       46903  46902      2505   \n",
       "46903       46904  46903      2505   \n",
       "46906       46907  46906      2505   \n",
       "46910       46911  46910      2505   \n",
       "46912       46913  46912      2505   \n",
       "\n",
       "                                                    text party  term   comp  \\\n",
       "177    And that choir, or that singing and choral gro...   dem  1968   True   \n",
       "179    VOICES:  We Want Humphrey! VICE PRESIDENT HUMP...   dem  1968   True   \n",
       "184    VOICES:  We want Humphrey!   VICE PRESIDENT HU...   dem  1968   True   \n",
       "185    VOICES:  You!  You! VICE PRESIDENT HUMPHREY:  ...   dem  1968   True   \n",
       "186    VOICES:  Humphrey!  Humphrey! VICE PRESIDENT H...   dem  1968   True   \n",
       "...                                                  ...   ...   ...    ...   \n",
       "46902  Q. My question for you today, sir, is, how do ...   rep  1976   True   \n",
       "46903  Q. Washington, Oregon, and Montana are three s...   rep  1976   True   \n",
       "46906  Q. First, I commend you on being able to prono...   rep  1976  False   \n",
       "46910  Q. If we can have the burden, we'll take the r...   rep  1976   True   \n",
       "46912  Q. How much time do you spend with radio? Is r...   rep  1976  False   \n",
       "\n",
       "      populist_old_keywords  par_id speech_par_id  length  \n",
       "177                   False       1        2133_1      36  \n",
       "179                   False       3        2133_3      51  \n",
       "184                   False       8        2133_8      82  \n",
       "185                   False       9        2133_9      26  \n",
       "186                   False      10       2133_10      21  \n",
       "...                     ...     ...           ...     ...  \n",
       "46902                 False       6        2505_6      81  \n",
       "46903                 False       7        2505_7      63  \n",
       "46906                 False      10       2505_10      91  \n",
       "46910                 False      14       2505_14      89  \n",
       "46912                 False      16       2505_16      15  \n",
       "\n",
       "[1500 rows x 11 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junk_qa_df.iloc[0:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = []\n",
    "for i in range(len(all_paras['text'])):\n",
    "    if re.search('\\. Q\\.|Q\\.|QUESTION\\.|Question\\.', all_paras['text'][i]) is not None:\n",
    "        qa.append(all_paras.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df = pd.DataFrame(qa)\n",
    "qa_speech = qa_df['Speech_id'].unique()\n",
    "qa_speech_df = pd.DataFrame(qa_speech)\n",
    "qa_speech_df.to_csv(\"q&a_speeches.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_speech_df = pd.read_csv(\"q&a_speeches.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speech_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2012-10-29-and-exchange-with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2012-09-20-question-and-answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2004-09-10-discussion-portsmouth-ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2004-09-04-broadview-heights-ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2004-10-04-discussion-clive-iowa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2004-11-02-reporters-columbus-ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2004-11-02-reporters-crawford-texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2004-09-21-and-exchange-with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2004-09-20-derry-new-hampshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2004-09-07-discussion-sedalia-missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2012-09-25-new-york-city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2020-09-17-field-moosic-pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2012-10-10-mount-vernon-ohio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Speech_id\n",
       "0                                     3005\n",
       "1                                     2455\n",
       "2                                     2874\n",
       "3                                     2450\n",
       "4                                     2487\n",
       "5                                     3003\n",
       "6                                     1402\n",
       "7                                     2839\n",
       "8                                     2781\n",
       "9                                     2794\n",
       "10                                    2838\n",
       "11                                    2379\n",
       "12                                    1103\n",
       "13                                    2397\n",
       "14                                    3076\n",
       "15                                    2382\n",
       "16                                    2802\n",
       "17                                    2814\n",
       "18                                    2987\n",
       "19                                    2364\n",
       "20                                    2836\n",
       "21                                    2413\n",
       "22                                    2016\n",
       "23                                    2821\n",
       "24                                    2388\n",
       "25                                    2808\n",
       "26                                    2834\n",
       "27                                    2820\n",
       "28                                    2458\n",
       "29                                    2505\n",
       "30                                    2507\n",
       "31                                    2710\n",
       "32                                    2512\n",
       "33            2012-10-29-and-exchange-with\n",
       "34          2012-09-20-question-and-answer\n",
       "35   2004-09-10-discussion-portsmouth-ohio\n",
       "36       2004-09-04-broadview-heights-ohio\n",
       "37        2004-10-04-discussion-clive-iowa\n",
       "38      2004-11-02-reporters-columbus-ohio\n",
       "39     2004-11-02-reporters-crawford-texas\n",
       "40            2004-09-21-and-exchange-with\n",
       "41          2004-09-20-derry-new-hampshire\n",
       "42  2004-09-07-discussion-sedalia-missouri\n",
       "43                2012-09-25-new-york-city\n",
       "44    2020-09-17-field-moosic-pennsylvania\n",
       "45            2012-10-10-mount-vernon-ohio"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_speech_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "junk_qa_df_1 = junk_qa_df.iloc[0:1500]\n",
    "junk_qa_df_1_cleaned = junk_qa_df_1[~junk_qa_df_1['Speech_id'].isin(qa_speech_df[\"Speech_id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177      False\n",
       "179      False\n",
       "184      False\n",
       "185      False\n",
       "186      False\n",
       "         ...  \n",
       "46902     True\n",
       "46903     True\n",
       "46906     True\n",
       "46910     True\n",
       "46912     True\n",
       "Name: Speech_id, Length: 1500, dtype: bool"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junk_qa_df_1['Speech_id'].isin(qa_speech_df[\"Speech_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "junk_qa_df_1_cleaned.to_csv(\"junk_text_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X</th>\n",
       "      <th>Speech_id</th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "      <th>term</th>\n",
       "      <th>comp</th>\n",
       "      <th>populist_old_keywords</th>\n",
       "      <th>par_id</th>\n",
       "      <th>speech_par_id</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>2133</td>\n",
       "      <td>And that choir, or that singing and choral gro...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1968</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2133_1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>180</td>\n",
       "      <td>179</td>\n",
       "      <td>2133</td>\n",
       "      <td>VOICES:  We Want Humphrey! VICE PRESIDENT HUMP...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1968</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2133_3</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>185</td>\n",
       "      <td>184</td>\n",
       "      <td>2133</td>\n",
       "      <td>VOICES:  We want Humphrey!   VICE PRESIDENT HU...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1968</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2133_8</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>186</td>\n",
       "      <td>185</td>\n",
       "      <td>2133</td>\n",
       "      <td>VOICES:  You!  You! VICE PRESIDENT HUMPHREY:  ...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1968</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>2133_9</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>2133</td>\n",
       "      <td>VOICES:  Humphrey!  Humphrey! VICE PRESIDENT H...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1968</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>2133_10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46575</th>\n",
       "      <td>46576</td>\n",
       "      <td>46575</td>\n",
       "      <td>2707</td>\n",
       "      <td>THE TRUTH ABOUT OUR FUTURE: Second, I believe ...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1984</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>2707_15</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46582</th>\n",
       "      <td>46583</td>\n",
       "      <td>46582</td>\n",
       "      <td>2707</td>\n",
       "      <td>NEW POPULISM: Third, Mr. Reagan and I differ o...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1984</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>2707_22</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46588</th>\n",
       "      <td>46589</td>\n",
       "      <td>46588</td>\n",
       "      <td>2707</td>\n",
       "      <td>ARMS CONTROL: Finally, Mr. Reagan and I disagr...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1984</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>2707_28</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46591</th>\n",
       "      <td>46592</td>\n",
       "      <td>46591</td>\n",
       "      <td>2707</td>\n",
       "      <td>Mr. Reagan is the first president since Hoover...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1984</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>2707_31</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46882</th>\n",
       "      <td>46883</td>\n",
       "      <td>46882</td>\n",
       "      <td>2277</td>\n",
       "      <td>We need something more from the Republican can...</td>\n",
       "      <td>dem</td>\n",
       "      <td>1972</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "      <td>2277_21</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1163 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      X Speech_id  \\\n",
       "177           178    177      2133   \n",
       "179           180    179      2133   \n",
       "184           185    184      2133   \n",
       "185           186    185      2133   \n",
       "186           187    186      2133   \n",
       "...           ...    ...       ...   \n",
       "46575       46576  46575      2707   \n",
       "46582       46583  46582      2707   \n",
       "46588       46589  46588      2707   \n",
       "46591       46592  46591      2707   \n",
       "46882       46883  46882      2277   \n",
       "\n",
       "                                                    text party  term  comp  \\\n",
       "177    And that choir, or that singing and choral gro...   dem  1968  True   \n",
       "179    VOICES:  We Want Humphrey! VICE PRESIDENT HUMP...   dem  1968  True   \n",
       "184    VOICES:  We want Humphrey!   VICE PRESIDENT HU...   dem  1968  True   \n",
       "185    VOICES:  You!  You! VICE PRESIDENT HUMPHREY:  ...   dem  1968  True   \n",
       "186    VOICES:  Humphrey!  Humphrey! VICE PRESIDENT H...   dem  1968  True   \n",
       "...                                                  ...   ...   ...   ...   \n",
       "46575  THE TRUTH ABOUT OUR FUTURE: Second, I believe ...   dem  1984  True   \n",
       "46582  NEW POPULISM: Third, Mr. Reagan and I differ o...   dem  1984  True   \n",
       "46588  ARMS CONTROL: Finally, Mr. Reagan and I disagr...   dem  1984  True   \n",
       "46591  Mr. Reagan is the first president since Hoover...   dem  1984  True   \n",
       "46882  We need something more from the Republican can...   dem  1972  True   \n",
       "\n",
       "      populist_old_keywords  par_id speech_par_id  length  \n",
       "177                   False       1        2133_1      36  \n",
       "179                   False       3        2133_3      51  \n",
       "184                   False       8        2133_8      82  \n",
       "185                   False       9        2133_9      26  \n",
       "186                   False      10       2133_10      21  \n",
       "...                     ...     ...           ...     ...  \n",
       "46575                 False      15       2707_15      77  \n",
       "46582                 False      22       2707_22      40  \n",
       "46588                 False      28       2707_28      82  \n",
       "46591                 False      31       2707_31      53  \n",
       "46882                  True      21       2277_21      68  \n",
       "\n",
       "[1163 rows x 11 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junk_qa_df_1_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
