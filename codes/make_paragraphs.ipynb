{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract paragraphs, combine short paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yuchenluo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3a08088fe17c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m#get meta data of the speech\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mcand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-speech.*\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mterm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"speech-(.*)-\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"speech-(.*).txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mpars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "col_names = [\"text\",\"candidate\", \"term\", \"title\", \"comp\"]\n",
    "rows = []\n",
    "for root, dirs, files, in os.walk('/Users/yuchenluo/Desktop/Measure_RadicalDiscourse'):\n",
    "    for file in files:\n",
    "        if file.endswith('txt'):\n",
    "            speech = open(os.path.join(root, file), \"r\").read()\n",
    "            #speech = f.read()\n",
    "            #get meta data of the speech\n",
    "            cand = re.sub(\"-speech.*\", \"\", file)\n",
    "            term = re.search(\"speech-(.*)-\", file).group(1)[0:4]\n",
    "            title = re.search(\"speech-(.*).txt\", file).group(1)\n",
    "            pars = speech.split('\\n')\n",
    "            pars = [i for i in pars if i] #remove empty strings\n",
    "            pars = [re.sub(\" \\[[^()]*\\]\", \"\", par) for par in pars] #remove strings inside brackets\n",
    "            # loop through all paragraphs inside each speech \n",
    "            i = 0    \n",
    "            while i < (len(pars) - 1):\n",
    "                n_sent = len(sent_tokenize(pars[i]))\n",
    "                if n_sent >2:\n",
    "                    row = [pars[i], cand, term, title, False]\n",
    "                    rows.append(row)\n",
    "                    i += 1\n",
    "                elif i < len(pars) - 1:\n",
    "                    row = [pars[i] + \" \" + pars[i +1], cand, term, title, True]\n",
    "                    i += 2\n",
    "                    if len(sent_tokenize(row[0])) < 3 and i < len(pars) - 1:\n",
    "                        row_2 = [row[0] + \" \" + pars[i], cand, term, title, True]\n",
    "                        i += 1\n",
    "                        rows.append(row_2)\n",
    "                    else: \n",
    "                        rows.append(row)\n",
    "                else: \n",
    "                    row = [pars[i - 1] + \" \" + pars[i], cand, term, title, True]\n",
    "                    rows.pop()\n",
    "                    rows.append(row)\n",
    "                            \n",
    "                                \n",
    "                            \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rows[0:10]  #check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"paragraphs.csv\", 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)   \n",
    "    writer.writerow(col_names)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat the process for Annenberg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "annen_meta = pd.read_csv(\"/Users/yuchenluo/Desktop/Measure_RadicalDiscourse/annenberg_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "root = \"/Users/yuchenluo/Desktop/Measure_RadicalDiscourse/Annenberg-data\" \n",
    "col_names = [\"Speech_id\",\"text\",\"party\", \"term\", \"comp\"] \n",
    "rows = [] \n",
    "\n",
    "for file in os.listdir('/Users/yuchenluo/Desktop/Measure_RadicalDiscourse/Annenberg-data'): \n",
    "    if file.endswith('txt'): \n",
    "        speech = open(os.path.join(root, file), \"r\").read() \n",
    "        #get meta data of the speech \n",
    "        id_speech = re.search('File_(.*).txt', file).group(1) \n",
    "        party = annen_meta[annen_meta['id_speech'] == float(id_speech)]['party'].iloc[0] \n",
    "        term = annen_meta[annen_meta['id_speech'] == float(id_speech)]['year'].iloc[0] \n",
    "        pars = speech.split('\\n\\n') \n",
    "        # the last paragraph is not part of body text\n",
    "        del pars[-1] \n",
    "        pars = [i for i in pars if i] #remove empty strings \n",
    "        pars = [re.sub(\" \\[[^()]*\\]\", \"\", par) for par in pars] #remove strings inside brackets \n",
    "        pars = [re.sub(\"\\t\", \"\",par) for par in pars]\n",
    "        pars = [re.sub(\"\\n\", \"\",par) for par in pars] # remove \\t and \\n\n",
    "        # loop through all paragraphs inside each speech  \n",
    "        i = 0     \n",
    "        while i < (len(pars) - 1): \n",
    "            n_sent = len(sent_tokenize(pars[i])) \n",
    "            if n_sent >2: \n",
    "                row = [id_speech, pars[i], party, term, False] \n",
    "                rows.append(row) \n",
    "                i += 1 \n",
    "            elif i < len(pars) - 1: \n",
    "                row = [id_speech, pars[i] + \" \" + pars[i +1], party, term, True] \n",
    "                i += 2 \n",
    "                if len(sent_tokenize(row[0])) < 3 and i < len(pars) - 1: \n",
    "                    row_2 = [id_speech, row[0] + \" \" + pars[i], party, term, True] \n",
    "                    i += 1 \n",
    "                    rows.append(row_2) \n",
    "                else:  \n",
    "                    rows.append(row) \n",
    "            else:  \n",
    "                row = [id_speech, pars[i - 1] + \" \" + pars[i], party, term, True] \n",
    "                rows.pop() \n",
    "                rows.append(row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' To Chairman Dean and my great friend Dick Durbin; and to all my fellow citizens of this great nation; With profound gratitude and great humility, I accept your nomination for the presidency of the United States.']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"paragraphs_annenberg.csv\", 'w') as csvfile: \n",
    "    writer = csv.writer(csvfile)    \n",
    "    writer.writerow(col_names) \n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWhen we start talking about the economy, it's best that we get right to the point. Jimmy Carter promised the American people he would give them an inflation rate of four percent and an unemployment rate of four percent. There's no nice way to say it: he just plain broke his promise and by doing so, has shattered the hopes of millions and millions of Americans who are strapped to the wall by this unstable economy.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
