{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Fast Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.utils import tokenize\n",
    "import pandas as pd\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['when',\n",
       "  'we',\n",
       "  'start',\n",
       "  'talking',\n",
       "  'about',\n",
       "  'the',\n",
       "  'economy',\n",
       "  'it',\n",
       "  's',\n",
       "  'best',\n",
       "  'that',\n",
       "  'we',\n",
       "  'get',\n",
       "  'right',\n",
       "  'to',\n",
       "  'the',\n",
       "  'point',\n",
       "  'jimmy',\n",
       "  'carter',\n",
       "  'promised',\n",
       "  'the',\n",
       "  'american',\n",
       "  'people',\n",
       "  'he',\n",
       "  'would',\n",
       "  'give',\n",
       "  'them',\n",
       "  'an',\n",
       "  'inflation',\n",
       "  'rate',\n",
       "  'of',\n",
       "  'four',\n",
       "  'percent',\n",
       "  'and',\n",
       "  'an',\n",
       "  'unemployment',\n",
       "  'rate',\n",
       "  'of',\n",
       "  'four',\n",
       "  'percent',\n",
       "  'there',\n",
       "  's',\n",
       "  'no',\n",
       "  'nice',\n",
       "  'way',\n",
       "  'to',\n",
       "  'say',\n",
       "  'it',\n",
       "  'he',\n",
       "  'just',\n",
       "  'plain',\n",
       "  'broke',\n",
       "  'his',\n",
       "  'promise',\n",
       "  'and',\n",
       "  'by',\n",
       "  'doing',\n",
       "  'so',\n",
       "  'has',\n",
       "  'shattered',\n",
       "  'the',\n",
       "  'hopes',\n",
       "  'of',\n",
       "  'millions',\n",
       "  'and',\n",
       "  'millions',\n",
       "  'of',\n",
       "  'americans',\n",
       "  'who',\n",
       "  'are',\n",
       "  'strapped',\n",
       "  'to',\n",
       "  'the',\n",
       "  'wall',\n",
       "  'by',\n",
       "  'this',\n",
       "  'unstable',\n",
       "  'economy'],\n",
       " ['it',\n",
       "  's',\n",
       "  'no',\n",
       "  'secret',\n",
       "  'which',\n",
       "  'groups',\n",
       "  'are',\n",
       "  'hit',\n",
       "  'the',\n",
       "  'hardest',\n",
       "  'by',\n",
       "  'mr',\n",
       "  'carter',\n",
       "  's',\n",
       "  'inflationary',\n",
       "  'policies',\n",
       "  'the',\n",
       "  'elderly',\n",
       "  'in',\n",
       "  'america',\n",
       "  'have',\n",
       "  'become',\n",
       "  'prisoners',\n",
       "  'of',\n",
       "  'his',\n",
       "  'totally',\n",
       "  'inadequate',\n",
       "  'leadership',\n",
       "  'day',\n",
       "  'by',\n",
       "  'day',\n",
       "  'they',\n",
       "  'are',\n",
       "  'reminded',\n",
       "  'that',\n",
       "  'their',\n",
       "  'dollars',\n",
       "  'have',\n",
       "  'been',\n",
       "  'eaten',\n",
       "  'away',\n",
       "  'because',\n",
       "  'of',\n",
       "  'what',\n",
       "  'he',\n",
       "  'has',\n",
       "  'done',\n",
       "  'for',\n",
       "  'far',\n",
       "  'too',\n",
       "  'many',\n",
       "  'their',\n",
       "  'homes',\n",
       "  'whether',\n",
       "  'they',\n",
       "  'rent',\n",
       "  'or',\n",
       "  'buy',\n",
       "  'have',\n",
       "  'become',\n",
       "  'impossible',\n",
       "  'burdens',\n",
       "  'taking',\n",
       "  'maybe',\n",
       "  'percent',\n",
       "  'of',\n",
       "  'meager',\n",
       "  'retirement',\n",
       "  'incomes'],\n",
       " ['how',\n",
       "  'can',\n",
       "  'our',\n",
       "  'elderly',\n",
       "  'who',\n",
       "  'have',\n",
       "  'worked',\n",
       "  'so',\n",
       "  'hard',\n",
       "  'to',\n",
       "  'enjoy',\n",
       "  'their',\n",
       "  'retirement',\n",
       "  'years',\n",
       "  'be',\n",
       "  'expected',\n",
       "  'to',\n",
       "  'survive',\n",
       "  'on',\n",
       "  'limited',\n",
       "  'incomes',\n",
       "  'while',\n",
       "  'this',\n",
       "  'president',\n",
       "  'and',\n",
       "  'this',\n",
       "  'administration',\n",
       "  'do',\n",
       "  'all',\n",
       "  'they',\n",
       "  'can',\n",
       "  'to',\n",
       "  'run',\n",
       "  'away',\n",
       "  'from',\n",
       "  'the',\n",
       "  'problems',\n",
       "  'we',\n",
       "  're',\n",
       "  'not',\n",
       "  'talking',\n",
       "  'about',\n",
       "  'numbers',\n",
       "  'here',\n",
       "  'we',\n",
       "  're',\n",
       "  'talking',\n",
       "  'about',\n",
       "  'real',\n",
       "  'people',\n",
       "  'with',\n",
       "  'real',\n",
       "  'concerns',\n",
       "  'with',\n",
       "  'real',\n",
       "  'utility',\n",
       "  'bills',\n",
       "  'and',\n",
       "  'real',\n",
       "  'food',\n",
       "  'bills',\n",
       "  'that',\n",
       "  's',\n",
       "  'why',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'issues',\n",
       "  'in',\n",
       "  'this',\n",
       "  'campaign',\n",
       "  'is',\n",
       "  'the',\n",
       "  'security',\n",
       "  'of',\n",
       "  'the',\n",
       "  'social',\n",
       "  'security',\n",
       "  'system',\n",
       "  'mr',\n",
       "  'carter',\n",
       "  'has',\n",
       "  'gone',\n",
       "  'around',\n",
       "  'the',\n",
       "  'nation',\n",
       "  'telling',\n",
       "  'the',\n",
       "  'people',\n",
       "  'of',\n",
       "  'america',\n",
       "  'that',\n",
       "  'i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'support',\n",
       "  'social',\n",
       "  'security',\n",
       "  'that',\n",
       "  's',\n",
       "  'just',\n",
       "  'not',\n",
       "  'true'],\n",
       " ['i',\n",
       "  'believe',\n",
       "  'that',\n",
       "  'social',\n",
       "  'security',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'this',\n",
       "  'nation',\n",
       "  's',\n",
       "  'most',\n",
       "  'vital',\n",
       "  'commitments',\n",
       "  'to',\n",
       "  'our',\n",
       "  'senior',\n",
       "  'citizens',\n",
       "  'i',\n",
       "  'will',\n",
       "  'preserve',\n",
       "  'and',\n",
       "  'strengthen',\n",
       "  'this',\n",
       "  'fundamental',\n",
       "  'contract',\n",
       "  'between',\n",
       "  'the',\n",
       "  'american',\n",
       "  'people',\n",
       "  'and',\n",
       "  'their',\n",
       "  'government',\n",
       "  'indeed',\n",
       "  'it',\n",
       "  'is',\n",
       "  'mr',\n",
       "  'carter',\n",
       "  'who',\n",
       "  'has',\n",
       "  'endangered',\n",
       "  'the',\n",
       "  'economic',\n",
       "  'security',\n",
       "  'of',\n",
       "  'senior',\n",
       "  'citizens',\n",
       "  'not',\n",
       "  'only',\n",
       "  'is',\n",
       "  'his',\n",
       "  'inflation',\n",
       "  'eating',\n",
       "  'away',\n",
       "  'the',\n",
       "  'value',\n",
       "  'of',\n",
       "  'the',\n",
       "  'savings',\n",
       "  'of',\n",
       "  'older',\n",
       "  'americans',\n",
       "  'but',\n",
       "  'his',\n",
       "  'unemployment',\n",
       "  'is',\n",
       "  'robbing',\n",
       "  'the',\n",
       "  'social',\n",
       "  'security',\n",
       "  'trust',\n",
       "  'fund',\n",
       "  'of',\n",
       "  'needed',\n",
       "  'revenue',\n",
       "  'and',\n",
       "  'it',\n",
       "  'was',\n",
       "  'his',\n",
       "  'advisory',\n",
       "  'council',\n",
       "  'on',\n",
       "  'social',\n",
       "  'security',\n",
       "  'that',\n",
       "  'recommended',\n",
       "  'taxing',\n",
       "  'social',\n",
       "  'security',\n",
       "  'benefits',\n",
       "  'benefits',\n",
       "  'that',\n",
       "  'have',\n",
       "  'already',\n",
       "  'been',\n",
       "  'paid',\n",
       "  'for',\n",
       "  'by',\n",
       "  'taxes'],\n",
       " ['in',\n",
       "  'contrast',\n",
       "  'i',\n",
       "  'am',\n",
       "  'committed',\n",
       "  'to',\n",
       "  'an',\n",
       "  'economic',\n",
       "  'program',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'inflation',\n",
       "  'and',\n",
       "  'put',\n",
       "  'people',\n",
       "  'back',\n",
       "  'to',\n",
       "  'work',\n",
       "  'and',\n",
       "  'i',\n",
       "  'would',\n",
       "  'veto',\n",
       "  'any',\n",
       "  'attempt',\n",
       "  'to',\n",
       "  'tax',\n",
       "  'social',\n",
       "  'security',\n",
       "  'benefits',\n",
       "  'but',\n",
       "  'there',\n",
       "  'is',\n",
       "  'another',\n",
       "  'injustice',\n",
       "  'done',\n",
       "  'to',\n",
       "  'older',\n",
       "  'americans',\n",
       "  'that',\n",
       "  'concerns',\n",
       "  'me',\n",
       "  'deeply',\n",
       "  'and',\n",
       "  'that',\n",
       "  'is',\n",
       "  'the',\n",
       "  'social',\n",
       "  'security',\n",
       "  'earnings',\n",
       "  'limitation',\n",
       "  'which',\n",
       "  'forces',\n",
       "  'retirees',\n",
       "  'to',\n",
       "  'give',\n",
       "  'up',\n",
       "  'in',\n",
       "  'benefits',\n",
       "  'for',\n",
       "  'every',\n",
       "  'they',\n",
       "  'make',\n",
       "  'above',\n",
       "  'thus',\n",
       "  'if',\n",
       "  'a',\n",
       "  'person',\n",
       "  'earns',\n",
       "  'more',\n",
       "  'than',\n",
       "  'a',\n",
       "  'year',\n",
       "  'not',\n",
       "  'only',\n",
       "  'must',\n",
       "  'he',\n",
       "  'or',\n",
       "  'she',\n",
       "  'pay',\n",
       "  'social',\n",
       "  'security',\n",
       "  'and',\n",
       "  'income',\n",
       "  'taxes',\n",
       "  'but',\n",
       "  'he',\n",
       "  'or',\n",
       "  'she',\n",
       "  'must',\n",
       "  'also',\n",
       "  'lose',\n",
       "  'o',\n",
       "  'percent',\n",
       "  'of',\n",
       "  'every',\n",
       "  'additional',\n",
       "  'dollar',\n",
       "  'earned']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make corpus \n",
    "# df = pd.read_csv(\"20201115_all_paragraphs.csv\")\n",
    "# corpus = df['text'].tolist()\n",
    "# corpus = [list(tokenize(string, lowercase = True, deacc = True)) for string in corpus]\n",
    "\n",
    "#check the tokenizer results\n",
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained fast text \n",
    "model_pretrain = FastText(size=300, window=5, min_count=10)\n",
    "model_pretrain.build_vocab(sentences=corpus)\n",
    "\n",
    "\n",
    "# train 5 epochs on top of fast text\n",
    "model_train_5 = FastText(size=300, window=5, min_count=10, sentences=corpus, iter=5)\n",
    "\n",
    "# train 10 epochs on top of fast text\n",
    "model_train_10 = FastText(size=300, window=5, min_count=10, sentences=corpus, iter=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vectors\n",
    "pretrain_vectors = model_pretrain.wv\n",
    "train_5_vectors = model_train_5.wv\n",
    "train_10_vectors = model_train_10.wv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pretrained_embeddings.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    words = pretrain_vectors.vocab.keys()\n",
    "    for word in words:\n",
    "        vector = pretrain_vectors.get_vector(word).tolist()\n",
    "        row = [word] + vector\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_5_embeddings.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    words = train_5_vectors.vocab.keys()\n",
    "    for word in words:\n",
    "        vector = train_5_vectors.get_vector(word).tolist()\n",
    "        row = [word] + vector\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_10_embeddings.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    words = train_10_vectors.vocab.keys()\n",
    "    for word in words:\n",
    "        vector = train_10_vectors.get_vector(word).tolist()\n",
    "        row = [word] + vector\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      when  1.0872998237609863  -0.5678383708000183  -0.8449351787567139  \\\n",
      "0       we           -1.953811             1.428439             1.014504   \n",
      "1    start           -0.180253             2.054194             0.156868   \n",
      "2  talking            1.661466            -0.964927            -0.143938   \n",
      "3    about            2.512414            -0.161493            -0.578523   \n",
      "4      the            0.201328            -1.605674             3.944529   \n",
      "\n",
      "   0.20961891114711761  -0.2547917068004608  -0.4416848123073578  \\\n",
      "0             0.608150             0.477313            -1.286874   \n",
      "1            -1.737676             0.221800            -0.397544   \n",
      "2             0.065968            -0.089344            -1.405889   \n",
      "3             2.123414            -1.070833             0.295102   \n",
      "4            -1.365157            -0.124232             0.118243   \n",
      "\n",
      "   -0.5884577631950378  0.924308180809021  0.726588249206543  ...  \\\n",
      "0            -3.103490           7.470490           0.854380  ...   \n",
      "1             0.036900           0.955967           0.776679  ...   \n",
      "2            -0.329027           1.533125          -0.295764  ...   \n",
      "3            -0.831250           0.446934           0.221236  ...   \n",
      "4            -0.733099          -0.972703           0.447869  ...   \n",
      "\n",
      "   0.945688784122467  -0.9234957098960876  -3.721527099609375  \\\n",
      "0          -0.674852             1.178615            3.676805   \n",
      "1          -0.463715             0.149243           -0.388582   \n",
      "2           1.119406            -0.219119            0.162995   \n",
      "3           1.119262            -0.758747           -0.547654   \n",
      "4           0.557067             1.188197           -0.092331   \n",
      "\n",
      "   -0.4465535879135132  -0.929984450340271  -0.6987674236297607  \\\n",
      "0            -3.078219           -2.815809             0.465505   \n",
      "1            -0.111825            2.310508            -0.110678   \n",
      "2            -1.903910            0.118651             0.406409   \n",
      "3            -0.497086            1.904831             0.731917   \n",
      "4            -1.819357            0.286294            -0.903330   \n",
      "\n",
      "   -0.35493195056915283  -0.6633405089378357  1.6753792762756348  \\\n",
      "0             -5.504439            -1.444357           -1.140654   \n",
      "1             -0.826468             0.075353            0.947346   \n",
      "2              2.877201            -1.408342            0.430729   \n",
      "3             -1.597469            -0.171950            0.666174   \n",
      "4              2.311605            -0.092911            0.288623   \n",
      "\n",
      "   0.9805627465248108  \n",
      "0           -2.407896  \n",
      "1           -0.826625  \n",
      "2            0.176480  \n",
      "3            0.617734  \n",
      "4            4.068092  \n",
      "\n",
      "[5 rows x 301 columns]\n"
     ]
    }
   ],
   "source": [
    "# check embeddings \n",
    "print(pd.read_csv(\"pretrained_embeddings.csv\").head())\n",
    "print(pd.read_csv(\"train_5_embeddings.csv\").head())\n",
    "print(pd.read_csv(\"train_10_embeddings.csv\").head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
